{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like Guevara, we estimate the values in the weight matrix by partial least squares regression.\n",
    "\n",
    "In our case:\n",
    "    1. The independent variables for the regression equations are the dimensions of the corpus based vectors of the component nouns.\n",
    "    2. The AN vectors provide the dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PLSRegression(copy=True, max_iter=500, n_components=2, scale=True, tol=1e-06)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample PLR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# load boston data using sklearn datasets\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "# separate data and target values\n",
    "x = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# tabular data structure with labeled axes\n",
    "# (rows and columns) using DataFrame\n",
    "df_x = pd.DataFrame(x, columns=boston.feature_names)\n",
    "df_y = pd.DataFrame(y)\n",
    "\n",
    "# create PLSRegression model\n",
    "pls2 = PLSRegression(n_components=2)\n",
    "\n",
    "# split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.30, random_state=1)\n",
    "\n",
    "# fit the model\n",
    "model=pls2.fit(x_train, y_train)\n",
    "\n",
    "# predict the values\n",
    "Y_pred = pls2.predict(x_test)\n",
    "\n",
    "# plot the predicted Values\n",
    "plt.plot(Y_pred)\n",
    "plt.xticks(rotation=90)\n",
    "print (plt.show())\n",
    "\n",
    "# print the predicted value\n",
    "# print(Y_pred)\n",
    "\n",
    "PLSRegression()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PLSRegression(copy=True, max_iter=500, n_components=2, scale=True, tol=1e-06)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pls2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 512) (194, 512)\n",
      "x_train (135, 512) y_train (135, 512)\n",
      "x_test (59, 512) y_test (59, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7075378163068997"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for text only\n",
    "# learning adjective matrices\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# x-axis should be nouns\n",
    "# y-axis should be adjective-nouns\n",
    "\n",
    "# separate data and target values\n",
    "x = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/openl3_noun_embeddings.csv\")\n",
    "y = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/openl3_adjnoun_embeddings.csv\")\n",
    "\n",
    "df_x= x.loc[:, x.columns!=x.columns[0]]\n",
    "df_y= y.loc[:, y.columns!=y.columns[0]]\n",
    "\n",
    "print(df_x.shape, df_y.shape)\n",
    "\n",
    "\n",
    "# create PLSRegression model\n",
    "pls2 = PLSRegression(n_components=2)\n",
    "\n",
    "# split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.30, random_state=1)\n",
    "\n",
    "# fit the model\n",
    "pls2.fit(x_train, y_train)\n",
    "\n",
    "# predict the values\n",
    "Y_pred = pls2.predict(scale(y_test))\n",
    "\n",
    "# plot the predicted Values\n",
    "# plt.plot(Y_pred)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()\n",
    "\n",
    "# print the predicted value\n",
    "print (\"x_train\", x_train.shape, \"y_train\", y_train.shape)\n",
    "print (\"x_test\", x_test.shape, \"y_test\", y_test.shape)\n",
    "\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, pls2.predict(scale(y_test)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1, 19.9)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_decomposition import PLSRegression, PLSSVD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "n = len(x_train)\n",
    "\n",
    "# 10-fold CV, with shuffle\n",
    "kf_10 = model_selection.KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "mse = []\n",
    "\n",
    "for i in np.arange(1, 20):\n",
    "    pls = PLSRegression(n_components=i)\n",
    "    score = model_selection.cross_val_score(pls, scale(x_train), y_train, cv=kf_10, scoring='neg_mean_squared_error').mean()\n",
    "    mse.append(-score)\n",
    "\n",
    "# Plot results\n",
    "plt.plot(np.arange(1, 20), np.array(mse), '-v')\n",
    "plt.xlabel('Number of principal components in regression')\n",
    "plt.ylabel('MSE')\n",
    "# plt.title('Salary')\n",
    "plt.xlim(xmin=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.101676</td>\n",
       "      <td>0.166022</td>\n",
       "      <td>0.111098</td>\n",
       "      <td>-0.060879</td>\n",
       "      <td>0.141475</td>\n",
       "      <td>-0.080939</td>\n",
       "      <td>-0.132330</td>\n",
       "      <td>0.139669</td>\n",
       "      <td>-0.132435</td>\n",
       "      <td>-0.243054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402009</td>\n",
       "      <td>-0.321758</td>\n",
       "      <td>0.108202</td>\n",
       "      <td>0.245531</td>\n",
       "      <td>0.301240</td>\n",
       "      <td>0.046613</td>\n",
       "      <td>-0.158749</td>\n",
       "      <td>-0.057618</td>\n",
       "      <td>-0.271242</td>\n",
       "      <td>-0.141855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.100653</td>\n",
       "      <td>0.162312</td>\n",
       "      <td>0.119864</td>\n",
       "      <td>-0.068043</td>\n",
       "      <td>0.133741</td>\n",
       "      <td>-0.087903</td>\n",
       "      <td>-0.135637</td>\n",
       "      <td>0.142704</td>\n",
       "      <td>-0.115222</td>\n",
       "      <td>-0.245092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397498</td>\n",
       "      <td>-0.327109</td>\n",
       "      <td>0.116580</td>\n",
       "      <td>0.241978</td>\n",
       "      <td>0.296280</td>\n",
       "      <td>0.063005</td>\n",
       "      <td>-0.174850</td>\n",
       "      <td>-0.065498</td>\n",
       "      <td>-0.277967</td>\n",
       "      <td>-0.146006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.106309</td>\n",
       "      <td>0.155667</td>\n",
       "      <td>0.107252</td>\n",
       "      <td>-0.073241</td>\n",
       "      <td>0.144105</td>\n",
       "      <td>-0.073491</td>\n",
       "      <td>-0.125416</td>\n",
       "      <td>0.142251</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.239835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406571</td>\n",
       "      <td>-0.334364</td>\n",
       "      <td>0.105403</td>\n",
       "      <td>0.240837</td>\n",
       "      <td>0.296747</td>\n",
       "      <td>0.041949</td>\n",
       "      <td>-0.175322</td>\n",
       "      <td>-0.054388</td>\n",
       "      <td>-0.276510</td>\n",
       "      <td>-0.138154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.100119</td>\n",
       "      <td>0.162584</td>\n",
       "      <td>0.121525</td>\n",
       "      <td>-0.068138</td>\n",
       "      <td>0.132338</td>\n",
       "      <td>-0.089580</td>\n",
       "      <td>-0.136709</td>\n",
       "      <td>0.142960</td>\n",
       "      <td>-0.112618</td>\n",
       "      <td>-0.245667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396433</td>\n",
       "      <td>-0.326906</td>\n",
       "      <td>0.118096</td>\n",
       "      <td>0.241814</td>\n",
       "      <td>0.295883</td>\n",
       "      <td>0.065906</td>\n",
       "      <td>-0.175976</td>\n",
       "      <td>-0.066973</td>\n",
       "      <td>-0.278572</td>\n",
       "      <td>-0.146946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.056343</td>\n",
       "      <td>0.243505</td>\n",
       "      <td>0.180198</td>\n",
       "      <td>0.020757</td>\n",
       "      <td>0.087308</td>\n",
       "      <td>-0.174954</td>\n",
       "      <td>-0.207066</td>\n",
       "      <td>0.128734</td>\n",
       "      <td>-0.068782</td>\n",
       "      <td>-0.279831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343446</td>\n",
       "      <td>-0.230741</td>\n",
       "      <td>0.166432</td>\n",
       "      <td>0.273224</td>\n",
       "      <td>0.321553</td>\n",
       "      <td>0.153308</td>\n",
       "      <td>-0.075126</td>\n",
       "      <td>-0.117708</td>\n",
       "      <td>-0.251043</td>\n",
       "      <td>-0.191316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>0.200287</td>\n",
       "      <td>0.166260</td>\n",
       "      <td>-0.031411</td>\n",
       "      <td>0.096477</td>\n",
       "      <td>-0.145878</td>\n",
       "      <td>-0.179410</td>\n",
       "      <td>0.139949</td>\n",
       "      <td>-0.063001</td>\n",
       "      <td>-0.267058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361205</td>\n",
       "      <td>-0.283531</td>\n",
       "      <td>0.156705</td>\n",
       "      <td>0.253239</td>\n",
       "      <td>0.302097</td>\n",
       "      <td>0.137608</td>\n",
       "      <td>-0.146418</td>\n",
       "      <td>-0.106111</td>\n",
       "      <td>-0.274042</td>\n",
       "      <td>-0.177013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.088568</td>\n",
       "      <td>0.180552</td>\n",
       "      <td>0.141476</td>\n",
       "      <td>-0.050267</td>\n",
       "      <td>0.116417</td>\n",
       "      <td>-0.115111</td>\n",
       "      <td>-0.156279</td>\n",
       "      <td>0.141241</td>\n",
       "      <td>-0.091267</td>\n",
       "      <td>-0.255431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380473</td>\n",
       "      <td>-0.306123</td>\n",
       "      <td>0.135231</td>\n",
       "      <td>0.247511</td>\n",
       "      <td>0.299296</td>\n",
       "      <td>0.097641</td>\n",
       "      <td>-0.160521</td>\n",
       "      <td>-0.084406</td>\n",
       "      <td>-0.275761</td>\n",
       "      <td>-0.160536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>0.147490</td>\n",
       "      <td>0.118085</td>\n",
       "      <td>-0.086744</td>\n",
       "      <td>0.134318</td>\n",
       "      <td>-0.080781</td>\n",
       "      <td>-0.127864</td>\n",
       "      <td>0.147174</td>\n",
       "      <td>-0.108203</td>\n",
       "      <td>-0.241656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401770</td>\n",
       "      <td>-0.345461</td>\n",
       "      <td>0.116020</td>\n",
       "      <td>0.234570</td>\n",
       "      <td>0.288616</td>\n",
       "      <td>0.062966</td>\n",
       "      <td>-0.202308</td>\n",
       "      <td>-0.064195</td>\n",
       "      <td>-0.287286</td>\n",
       "      <td>-0.142722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080601</td>\n",
       "      <td>0.198142</td>\n",
       "      <td>0.148372</td>\n",
       "      <td>-0.029364</td>\n",
       "      <td>0.111640</td>\n",
       "      <td>-0.128106</td>\n",
       "      <td>-0.168232</td>\n",
       "      <td>0.136930</td>\n",
       "      <td>-0.091568</td>\n",
       "      <td>-0.261015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372504</td>\n",
       "      <td>-0.284737</td>\n",
       "      <td>0.140321</td>\n",
       "      <td>0.255420</td>\n",
       "      <td>0.306811</td>\n",
       "      <td>0.106209</td>\n",
       "      <td>-0.132728</td>\n",
       "      <td>-0.090216</td>\n",
       "      <td>-0.266983</td>\n",
       "      <td>-0.167018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.106662</td>\n",
       "      <td>0.158896</td>\n",
       "      <td>0.101654</td>\n",
       "      <td>-0.067553</td>\n",
       "      <td>0.149100</td>\n",
       "      <td>-0.069359</td>\n",
       "      <td>-0.123696</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>-0.143473</td>\n",
       "      <td>-0.238700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409266</td>\n",
       "      <td>-0.329874</td>\n",
       "      <td>0.099990</td>\n",
       "      <td>0.243555</td>\n",
       "      <td>0.300393</td>\n",
       "      <td>0.031299</td>\n",
       "      <td>-0.163343</td>\n",
       "      <td>-0.049339</td>\n",
       "      <td>-0.271625</td>\n",
       "      <td>-0.135638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.095225</td>\n",
       "      <td>0.167210</td>\n",
       "      <td>0.133923</td>\n",
       "      <td>-0.065496</td>\n",
       "      <td>0.122028</td>\n",
       "      <td>-0.103049</td>\n",
       "      <td>-0.145888</td>\n",
       "      <td>0.144028</td>\n",
       "      <td>-0.094936</td>\n",
       "      <td>-0.250465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387925</td>\n",
       "      <td>-0.322153</td>\n",
       "      <td>0.129223</td>\n",
       "      <td>0.241940</td>\n",
       "      <td>0.294363</td>\n",
       "      <td>0.087007</td>\n",
       "      <td>-0.179274</td>\n",
       "      <td>-0.077931</td>\n",
       "      <td>-0.281312</td>\n",
       "      <td>-0.154366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.089592</td>\n",
       "      <td>0.174886</td>\n",
       "      <td>0.145086</td>\n",
       "      <td>-0.058571</td>\n",
       "      <td>0.112970</td>\n",
       "      <td>-0.116462</td>\n",
       "      <td>-0.155753</td>\n",
       "      <td>0.143842</td>\n",
       "      <td>-0.081387</td>\n",
       "      <td>-0.255467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379508</td>\n",
       "      <td>-0.313490</td>\n",
       "      <td>0.138983</td>\n",
       "      <td>0.243888</td>\n",
       "      <td>0.294950</td>\n",
       "      <td>0.105264</td>\n",
       "      <td>-0.175313</td>\n",
       "      <td>-0.087729</td>\n",
       "      <td>-0.281369</td>\n",
       "      <td>-0.161597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.065722</td>\n",
       "      <td>0.228881</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>0.006188</td>\n",
       "      <td>0.100193</td>\n",
       "      <td>-0.154255</td>\n",
       "      <td>-0.191186</td>\n",
       "      <td>0.130151</td>\n",
       "      <td>-0.086017</td>\n",
       "      <td>-0.271911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356384</td>\n",
       "      <td>-0.247663</td>\n",
       "      <td>0.152564</td>\n",
       "      <td>0.268572</td>\n",
       "      <td>0.318747</td>\n",
       "      <td>0.127630</td>\n",
       "      <td>-0.087791</td>\n",
       "      <td>-0.103595</td>\n",
       "      <td>-0.253371</td>\n",
       "      <td>-0.180301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.065711</td>\n",
       "      <td>0.220926</td>\n",
       "      <td>0.174593</td>\n",
       "      <td>-0.006951</td>\n",
       "      <td>0.090664</td>\n",
       "      <td>-0.161356</td>\n",
       "      <td>-0.193573</td>\n",
       "      <td>0.134942</td>\n",
       "      <td>-0.062948</td>\n",
       "      <td>-0.273685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351709</td>\n",
       "      <td>-0.258459</td>\n",
       "      <td>0.162901</td>\n",
       "      <td>0.262474</td>\n",
       "      <td>0.310834</td>\n",
       "      <td>0.148092</td>\n",
       "      <td>-0.114053</td>\n",
       "      <td>-0.113143</td>\n",
       "      <td>-0.263859</td>\n",
       "      <td>-0.184749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.087525</td>\n",
       "      <td>0.176088</td>\n",
       "      <td>0.151316</td>\n",
       "      <td>-0.058697</td>\n",
       "      <td>0.107717</td>\n",
       "      <td>-0.122819</td>\n",
       "      <td>-0.159854</td>\n",
       "      <td>0.144745</td>\n",
       "      <td>-0.071743</td>\n",
       "      <td>-0.257660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375474</td>\n",
       "      <td>-0.312503</td>\n",
       "      <td>0.144658</td>\n",
       "      <td>0.243366</td>\n",
       "      <td>0.293561</td>\n",
       "      <td>0.116105</td>\n",
       "      <td>-0.179185</td>\n",
       "      <td>-0.093258</td>\n",
       "      <td>-0.283516</td>\n",
       "      <td>-0.165150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.105971</td>\n",
       "      <td>0.144685</td>\n",
       "      <td>0.123031</td>\n",
       "      <td>-0.091706</td>\n",
       "      <td>0.129909</td>\n",
       "      <td>-0.084450</td>\n",
       "      <td>-0.129406</td>\n",
       "      <td>0.149118</td>\n",
       "      <td>-0.098011</td>\n",
       "      <td>-0.242667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399378</td>\n",
       "      <td>-0.349368</td>\n",
       "      <td>0.120799</td>\n",
       "      <td>0.232194</td>\n",
       "      <td>0.285422</td>\n",
       "      <td>0.072364</td>\n",
       "      <td>-0.212795</td>\n",
       "      <td>-0.068655</td>\n",
       "      <td>-0.291568</td>\n",
       "      <td>-0.144952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.090464</td>\n",
       "      <td>0.177126</td>\n",
       "      <td>0.138828</td>\n",
       "      <td>-0.053986</td>\n",
       "      <td>0.118464</td>\n",
       "      <td>-0.111341</td>\n",
       "      <td>-0.153207</td>\n",
       "      <td>0.141809</td>\n",
       "      <td>-0.093399</td>\n",
       "      <td>-0.253933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382816</td>\n",
       "      <td>-0.310180</td>\n",
       "      <td>0.133033</td>\n",
       "      <td>0.246211</td>\n",
       "      <td>0.298264</td>\n",
       "      <td>0.093649</td>\n",
       "      <td>-0.164625</td>\n",
       "      <td>-0.082112</td>\n",
       "      <td>-0.276848</td>\n",
       "      <td>-0.158569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.085750</td>\n",
       "      <td>0.177989</td>\n",
       "      <td>0.155517</td>\n",
       "      <td>-0.057370</td>\n",
       "      <td>0.104245</td>\n",
       "      <td>-0.127504</td>\n",
       "      <td>-0.163116</td>\n",
       "      <td>0.144997</td>\n",
       "      <td>-0.065978</td>\n",
       "      <td>-0.259351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372520</td>\n",
       "      <td>-0.310477</td>\n",
       "      <td>0.148403</td>\n",
       "      <td>0.243583</td>\n",
       "      <td>0.293232</td>\n",
       "      <td>0.123184</td>\n",
       "      <td>-0.179644</td>\n",
       "      <td>-0.096964</td>\n",
       "      <td>-0.284215</td>\n",
       "      <td>-0.167716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.069572</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.170437</td>\n",
       "      <td>-0.016067</td>\n",
       "      <td>0.093715</td>\n",
       "      <td>-0.154510</td>\n",
       "      <td>-0.187596</td>\n",
       "      <td>0.136661</td>\n",
       "      <td>-0.064582</td>\n",
       "      <td>-0.270843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355931</td>\n",
       "      <td>-0.267990</td>\n",
       "      <td>0.159637</td>\n",
       "      <td>0.259112</td>\n",
       "      <td>0.307803</td>\n",
       "      <td>0.142361</td>\n",
       "      <td>-0.125495</td>\n",
       "      <td>-0.109591</td>\n",
       "      <td>-0.267303</td>\n",
       "      <td>-0.181265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.084322</td>\n",
       "      <td>0.175776</td>\n",
       "      <td>0.163840</td>\n",
       "      <td>-0.062476</td>\n",
       "      <td>0.096985</td>\n",
       "      <td>-0.134597</td>\n",
       "      <td>-0.166853</td>\n",
       "      <td>0.147450</td>\n",
       "      <td>-0.050519</td>\n",
       "      <td>-0.261540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367954</td>\n",
       "      <td>-0.313922</td>\n",
       "      <td>0.156262</td>\n",
       "      <td>0.240893</td>\n",
       "      <td>0.289252</td>\n",
       "      <td>0.138471</td>\n",
       "      <td>-0.192346</td>\n",
       "      <td>-0.104421</td>\n",
       "      <td>-0.289702</td>\n",
       "      <td>-0.171863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.078927</td>\n",
       "      <td>0.194089</td>\n",
       "      <td>0.160058</td>\n",
       "      <td>-0.037760</td>\n",
       "      <td>0.101387</td>\n",
       "      <td>-0.137717</td>\n",
       "      <td>-0.173047</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>-0.069224</td>\n",
       "      <td>-0.263904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>-0.290757</td>\n",
       "      <td>0.151424</td>\n",
       "      <td>0.251148</td>\n",
       "      <td>0.300695</td>\n",
       "      <td>0.127873</td>\n",
       "      <td>-0.152433</td>\n",
       "      <td>-0.100704</td>\n",
       "      <td>-0.275337</td>\n",
       "      <td>-0.172692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.101706</td>\n",
       "      <td>0.161428</td>\n",
       "      <td>0.117048</td>\n",
       "      <td>-0.068428</td>\n",
       "      <td>0.136093</td>\n",
       "      <td>-0.084905</td>\n",
       "      <td>-0.133629</td>\n",
       "      <td>0.142407</td>\n",
       "      <td>-0.119350</td>\n",
       "      <td>-0.244035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399394</td>\n",
       "      <td>-0.327981</td>\n",
       "      <td>0.114041</td>\n",
       "      <td>0.242036</td>\n",
       "      <td>0.296718</td>\n",
       "      <td>0.058178</td>\n",
       "      <td>-0.173772</td>\n",
       "      <td>-0.063007</td>\n",
       "      <td>-0.277230</td>\n",
       "      <td>-0.144347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.101308</td>\n",
       "      <td>0.156735</td>\n",
       "      <td>0.124751</td>\n",
       "      <td>-0.076577</td>\n",
       "      <td>0.129206</td>\n",
       "      <td>-0.090500</td>\n",
       "      <td>-0.135881</td>\n",
       "      <td>0.145541</td>\n",
       "      <td>-0.103258</td>\n",
       "      <td>-0.245547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395739</td>\n",
       "      <td>-0.334470</td>\n",
       "      <td>0.121507</td>\n",
       "      <td>0.238166</td>\n",
       "      <td>0.291562</td>\n",
       "      <td>0.072884</td>\n",
       "      <td>-0.190747</td>\n",
       "      <td>-0.069958</td>\n",
       "      <td>-0.284122</td>\n",
       "      <td>-0.147771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.056815</td>\n",
       "      <td>0.232752</td>\n",
       "      <td>0.192612</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.076005</td>\n",
       "      <td>-0.182801</td>\n",
       "      <td>-0.209241</td>\n",
       "      <td>0.134827</td>\n",
       "      <td>-0.040694</td>\n",
       "      <td>-0.281649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338243</td>\n",
       "      <td>-0.245182</td>\n",
       "      <td>0.178699</td>\n",
       "      <td>0.265322</td>\n",
       "      <td>0.311466</td>\n",
       "      <td>0.177683</td>\n",
       "      <td>-0.108776</td>\n",
       "      <td>-0.128972</td>\n",
       "      <td>-0.264339</td>\n",
       "      <td>-0.196333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.095046</td>\n",
       "      <td>0.168641</td>\n",
       "      <td>0.132711</td>\n",
       "      <td>-0.063317</td>\n",
       "      <td>0.123156</td>\n",
       "      <td>-0.102422</td>\n",
       "      <td>-0.145849</td>\n",
       "      <td>0.143308</td>\n",
       "      <td>-0.097936</td>\n",
       "      <td>-0.250362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388351</td>\n",
       "      <td>-0.320267</td>\n",
       "      <td>0.127997</td>\n",
       "      <td>0.242911</td>\n",
       "      <td>0.295560</td>\n",
       "      <td>0.084546</td>\n",
       "      <td>-0.175236</td>\n",
       "      <td>-0.076823</td>\n",
       "      <td>-0.279752</td>\n",
       "      <td>-0.153936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.106072</td>\n",
       "      <td>0.147841</td>\n",
       "      <td>0.118484</td>\n",
       "      <td>-0.086397</td>\n",
       "      <td>0.133999</td>\n",
       "      <td>-0.081289</td>\n",
       "      <td>-0.128252</td>\n",
       "      <td>0.147142</td>\n",
       "      <td>-0.107770</td>\n",
       "      <td>-0.241849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401452</td>\n",
       "      <td>-0.345056</td>\n",
       "      <td>0.116363</td>\n",
       "      <td>0.234680</td>\n",
       "      <td>0.288680</td>\n",
       "      <td>0.063602</td>\n",
       "      <td>-0.202015</td>\n",
       "      <td>-0.064544</td>\n",
       "      <td>-0.287235</td>\n",
       "      <td>-0.142992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.089627</td>\n",
       "      <td>0.175530</td>\n",
       "      <td>0.144104</td>\n",
       "      <td>-0.057474</td>\n",
       "      <td>0.113850</td>\n",
       "      <td>-0.115765</td>\n",
       "      <td>-0.155487</td>\n",
       "      <td>0.143427</td>\n",
       "      <td>-0.083469</td>\n",
       "      <td>-0.255283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379964</td>\n",
       "      <td>-0.312607</td>\n",
       "      <td>0.138028</td>\n",
       "      <td>0.244405</td>\n",
       "      <td>0.295633</td>\n",
       "      <td>0.103379</td>\n",
       "      <td>-0.173060</td>\n",
       "      <td>-0.086842</td>\n",
       "      <td>-0.280459</td>\n",
       "      <td>-0.161167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.100879</td>\n",
       "      <td>0.153561</td>\n",
       "      <td>0.130565</td>\n",
       "      <td>-0.082252</td>\n",
       "      <td>0.124031</td>\n",
       "      <td>-0.094857</td>\n",
       "      <td>-0.137749</td>\n",
       "      <td>0.147786</td>\n",
       "      <td>-0.091360</td>\n",
       "      <td>-0.246760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392901</td>\n",
       "      <td>-0.338910</td>\n",
       "      <td>0.127116</td>\n",
       "      <td>0.235436</td>\n",
       "      <td>0.287874</td>\n",
       "      <td>0.083907</td>\n",
       "      <td>-0.202834</td>\n",
       "      <td>-0.075198</td>\n",
       "      <td>-0.289072</td>\n",
       "      <td>-0.150412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.097830</td>\n",
       "      <td>0.156124</td>\n",
       "      <td>0.138710</td>\n",
       "      <td>-0.081132</td>\n",
       "      <td>0.117227</td>\n",
       "      <td>-0.103531</td>\n",
       "      <td>-0.143562</td>\n",
       "      <td>0.148643</td>\n",
       "      <td>-0.079422</td>\n",
       "      <td>-0.249820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387414</td>\n",
       "      <td>-0.336382</td>\n",
       "      <td>0.134461</td>\n",
       "      <td>0.235271</td>\n",
       "      <td>0.286611</td>\n",
       "      <td>0.097870</td>\n",
       "      <td>-0.205938</td>\n",
       "      <td>-0.082406</td>\n",
       "      <td>-0.291199</td>\n",
       "      <td>-0.155212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.079022</td>\n",
       "      <td>0.193393</td>\n",
       "      <td>0.160617</td>\n",
       "      <td>-0.038811</td>\n",
       "      <td>0.100864</td>\n",
       "      <td>-0.137993</td>\n",
       "      <td>-0.173049</td>\n",
       "      <td>0.141027</td>\n",
       "      <td>-0.067817</td>\n",
       "      <td>-0.263945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366110</td>\n",
       "      <td>-0.291671</td>\n",
       "      <td>0.151992</td>\n",
       "      <td>0.250682</td>\n",
       "      <td>0.300123</td>\n",
       "      <td>0.129015</td>\n",
       "      <td>-0.154365</td>\n",
       "      <td>-0.101215</td>\n",
       "      <td>-0.276080</td>\n",
       "      <td>-0.172885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.074799</td>\n",
       "      <td>0.216780</td>\n",
       "      <td>0.145701</td>\n",
       "      <td>-0.004525</td>\n",
       "      <td>0.115112</td>\n",
       "      <td>-0.132401</td>\n",
       "      <td>-0.175208</td>\n",
       "      <td>0.130288</td>\n",
       "      <td>-0.108630</td>\n",
       "      <td>-0.263792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370105</td>\n",
       "      <td>-0.261256</td>\n",
       "      <td>0.136487</td>\n",
       "      <td>0.265640</td>\n",
       "      <td>0.318069</td>\n",
       "      <td>0.097519</td>\n",
       "      <td>-0.093284</td>\n",
       "      <td>-0.087482</td>\n",
       "      <td>-0.252924</td>\n",
       "      <td>-0.168498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.074748</td>\n",
       "      <td>0.215268</td>\n",
       "      <td>0.147889</td>\n",
       "      <td>-0.007072</td>\n",
       "      <td>0.113144</td>\n",
       "      <td>-0.133924</td>\n",
       "      <td>-0.175766</td>\n",
       "      <td>0.131237</td>\n",
       "      <td>-0.103937</td>\n",
       "      <td>-0.264186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369106</td>\n",
       "      <td>-0.263324</td>\n",
       "      <td>0.138621</td>\n",
       "      <td>0.264447</td>\n",
       "      <td>0.316504</td>\n",
       "      <td>0.101735</td>\n",
       "      <td>-0.098460</td>\n",
       "      <td>-0.089460</td>\n",
       "      <td>-0.255005</td>\n",
       "      <td>-0.169443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.092358</td>\n",
       "      <td>0.174694</td>\n",
       "      <td>0.134878</td>\n",
       "      <td>-0.056068</td>\n",
       "      <td>0.121688</td>\n",
       "      <td>-0.106699</td>\n",
       "      <td>-0.149845</td>\n",
       "      <td>0.141782</td>\n",
       "      <td>-0.098385</td>\n",
       "      <td>-0.252219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385733</td>\n",
       "      <td>-0.312890</td>\n",
       "      <td>0.129558</td>\n",
       "      <td>0.245671</td>\n",
       "      <td>0.298214</td>\n",
       "      <td>0.087128</td>\n",
       "      <td>-0.165465</td>\n",
       "      <td>-0.078639</td>\n",
       "      <td>-0.276633</td>\n",
       "      <td>-0.156055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.131202</td>\n",
       "      <td>0.099057</td>\n",
       "      <td>0.087876</td>\n",
       "      <td>-0.141272</td>\n",
       "      <td>0.157072</td>\n",
       "      <td>-0.034344</td>\n",
       "      <td>-0.088553</td>\n",
       "      <td>0.156709</td>\n",
       "      <td>-0.126205</td>\n",
       "      <td>-0.222752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430510</td>\n",
       "      <td>-0.403421</td>\n",
       "      <td>0.091628</td>\n",
       "      <td>0.214864</td>\n",
       "      <td>0.271632</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>-0.267585</td>\n",
       "      <td>-0.038201</td>\n",
       "      <td>-0.306103</td>\n",
       "      <td>-0.118815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.119734</td>\n",
       "      <td>0.122561</td>\n",
       "      <td>0.100203</td>\n",
       "      <td>-0.114181</td>\n",
       "      <td>0.148025</td>\n",
       "      <td>-0.054664</td>\n",
       "      <td>-0.106300</td>\n",
       "      <td>0.151597</td>\n",
       "      <td>-0.121384</td>\n",
       "      <td>-0.231192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417976</td>\n",
       "      <td>-0.375101</td>\n",
       "      <td>0.101308</td>\n",
       "      <td>0.224858</td>\n",
       "      <td>0.280645</td>\n",
       "      <td>0.036383</td>\n",
       "      <td>-0.233568</td>\n",
       "      <td>-0.048737</td>\n",
       "      <td>-0.295858</td>\n",
       "      <td>-0.129157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.086867</td>\n",
       "      <td>0.184653</td>\n",
       "      <td>0.142491</td>\n",
       "      <td>-0.045233</td>\n",
       "      <td>0.115811</td>\n",
       "      <td>-0.117577</td>\n",
       "      <td>-0.158727</td>\n",
       "      <td>0.140112</td>\n",
       "      <td>-0.092334</td>\n",
       "      <td>-0.256546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378975</td>\n",
       "      <td>-0.301088</td>\n",
       "      <td>0.135869</td>\n",
       "      <td>0.249464</td>\n",
       "      <td>0.301244</td>\n",
       "      <td>0.098582</td>\n",
       "      <td>-0.153445</td>\n",
       "      <td>-0.085232</td>\n",
       "      <td>-0.273431</td>\n",
       "      <td>-0.161727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.096345</td>\n",
       "      <td>0.178008</td>\n",
       "      <td>0.115428</td>\n",
       "      <td>-0.046536</td>\n",
       "      <td>0.138536</td>\n",
       "      <td>-0.089443</td>\n",
       "      <td>-0.140265</td>\n",
       "      <td>0.136655</td>\n",
       "      <td>-0.133259</td>\n",
       "      <td>-0.246743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396802</td>\n",
       "      <td>-0.307155</td>\n",
       "      <td>0.111329</td>\n",
       "      <td>0.250988</td>\n",
       "      <td>0.306483</td>\n",
       "      <td>0.051794</td>\n",
       "      <td>-0.139441</td>\n",
       "      <td>-0.061248</td>\n",
       "      <td>-0.265084</td>\n",
       "      <td>-0.146072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.102295</td>\n",
       "      <td>0.150635</td>\n",
       "      <td>0.129077</td>\n",
       "      <td>-0.085637</td>\n",
       "      <td>0.125117</td>\n",
       "      <td>-0.092372</td>\n",
       "      <td>-0.135566</td>\n",
       "      <td>0.148432</td>\n",
       "      <td>-0.091882</td>\n",
       "      <td>-0.245724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394433</td>\n",
       "      <td>-0.342440</td>\n",
       "      <td>0.125954</td>\n",
       "      <td>0.234184</td>\n",
       "      <td>0.286737</td>\n",
       "      <td>0.081874</td>\n",
       "      <td>-0.207114</td>\n",
       "      <td>-0.073928</td>\n",
       "      <td>-0.290370</td>\n",
       "      <td>-0.149150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.072373</td>\n",
       "      <td>0.212728</td>\n",
       "      <td>0.160226</td>\n",
       "      <td>-0.013685</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>-0.144708</td>\n",
       "      <td>-0.181642</td>\n",
       "      <td>0.134632</td>\n",
       "      <td>-0.081523</td>\n",
       "      <td>-0.267574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362180</td>\n",
       "      <td>-0.267509</td>\n",
       "      <td>0.150215</td>\n",
       "      <td>0.260845</td>\n",
       "      <td>0.311016</td>\n",
       "      <td>0.124238</td>\n",
       "      <td>-0.115830</td>\n",
       "      <td>-0.100499</td>\n",
       "      <td>-0.262631</td>\n",
       "      <td>-0.175706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.090157</td>\n",
       "      <td>0.171263</td>\n",
       "      <td>0.147734</td>\n",
       "      <td>-0.063975</td>\n",
       "      <td>0.110474</td>\n",
       "      <td>-0.117648</td>\n",
       "      <td>-0.155611</td>\n",
       "      <td>0.145575</td>\n",
       "      <td>-0.074498</td>\n",
       "      <td>-0.255597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378684</td>\n",
       "      <td>-0.318231</td>\n",
       "      <td>0.141698</td>\n",
       "      <td>0.241508</td>\n",
       "      <td>0.292058</td>\n",
       "      <td>0.110744</td>\n",
       "      <td>-0.185114</td>\n",
       "      <td>-0.090158</td>\n",
       "      <td>-0.285117</td>\n",
       "      <td>-0.162459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.101181</td>\n",
       "      <td>0.157292</td>\n",
       "      <td>0.124495</td>\n",
       "      <td>-0.075787</td>\n",
       "      <td>0.129461</td>\n",
       "      <td>-0.090461</td>\n",
       "      <td>-0.135989</td>\n",
       "      <td>0.145306</td>\n",
       "      <td>-0.104064</td>\n",
       "      <td>-0.245575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395774</td>\n",
       "      <td>-0.333754</td>\n",
       "      <td>0.121230</td>\n",
       "      <td>0.238504</td>\n",
       "      <td>0.291956</td>\n",
       "      <td>0.072310</td>\n",
       "      <td>-0.189391</td>\n",
       "      <td>-0.069719</td>\n",
       "      <td>-0.283618</td>\n",
       "      <td>-0.147720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.081086</td>\n",
       "      <td>0.194969</td>\n",
       "      <td>0.150729</td>\n",
       "      <td>-0.034106</td>\n",
       "      <td>0.109422</td>\n",
       "      <td>-0.129181</td>\n",
       "      <td>-0.168129</td>\n",
       "      <td>0.138457</td>\n",
       "      <td>-0.085473</td>\n",
       "      <td>-0.261140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371761</td>\n",
       "      <td>-0.288891</td>\n",
       "      <td>0.142732</td>\n",
       "      <td>0.253328</td>\n",
       "      <td>0.304266</td>\n",
       "      <td>0.111074</td>\n",
       "      <td>-0.141349</td>\n",
       "      <td>-0.092375</td>\n",
       "      <td>-0.270284</td>\n",
       "      <td>-0.167793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.098210</td>\n",
       "      <td>0.164486</td>\n",
       "      <td>0.126231</td>\n",
       "      <td>-0.066947</td>\n",
       "      <td>0.128434</td>\n",
       "      <td>-0.094746</td>\n",
       "      <td>-0.140259</td>\n",
       "      <td>0.143318</td>\n",
       "      <td>-0.106005</td>\n",
       "      <td>-0.247517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393172</td>\n",
       "      <td>-0.324920</td>\n",
       "      <td>0.122309</td>\n",
       "      <td>0.241938</td>\n",
       "      <td>0.295387</td>\n",
       "      <td>0.073884</td>\n",
       "      <td>-0.176940</td>\n",
       "      <td>-0.071129</td>\n",
       "      <td>-0.279512</td>\n",
       "      <td>-0.149785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.081687</td>\n",
       "      <td>0.196511</td>\n",
       "      <td>0.146421</td>\n",
       "      <td>-0.030949</td>\n",
       "      <td>0.113205</td>\n",
       "      <td>-0.125656</td>\n",
       "      <td>-0.166376</td>\n",
       "      <td>0.137058</td>\n",
       "      <td>-0.093741</td>\n",
       "      <td>-0.260084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374038</td>\n",
       "      <td>-0.286613</td>\n",
       "      <td>0.138636</td>\n",
       "      <td>0.254928</td>\n",
       "      <td>0.306547</td>\n",
       "      <td>0.103079</td>\n",
       "      <td>-0.133992</td>\n",
       "      <td>-0.088509</td>\n",
       "      <td>-0.267172</td>\n",
       "      <td>-0.165709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.094294</td>\n",
       "      <td>0.174451</td>\n",
       "      <td>0.127881</td>\n",
       "      <td>-0.054497</td>\n",
       "      <td>0.127658</td>\n",
       "      <td>-0.099964</td>\n",
       "      <td>-0.145744</td>\n",
       "      <td>0.140406</td>\n",
       "      <td>-0.109963</td>\n",
       "      <td>-0.249970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390025</td>\n",
       "      <td>-0.312619</td>\n",
       "      <td>0.123105</td>\n",
       "      <td>0.246834</td>\n",
       "      <td>0.300390</td>\n",
       "      <td>0.074719</td>\n",
       "      <td>-0.158935</td>\n",
       "      <td>-0.072410</td>\n",
       "      <td>-0.273463</td>\n",
       "      <td>-0.152238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.097229</td>\n",
       "      <td>0.156222</td>\n",
       "      <td>0.140855</td>\n",
       "      <td>-0.081583</td>\n",
       "      <td>0.115399</td>\n",
       "      <td>-0.105604</td>\n",
       "      <td>-0.144830</td>\n",
       "      <td>0.149057</td>\n",
       "      <td>-0.075889</td>\n",
       "      <td>-0.250514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386093</td>\n",
       "      <td>-0.336436</td>\n",
       "      <td>0.136437</td>\n",
       "      <td>0.234927</td>\n",
       "      <td>0.285957</td>\n",
       "      <td>0.101669</td>\n",
       "      <td>-0.207894</td>\n",
       "      <td>-0.084315</td>\n",
       "      <td>-0.292155</td>\n",
       "      <td>-0.156386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.093429</td>\n",
       "      <td>0.167747</td>\n",
       "      <td>0.140005</td>\n",
       "      <td>-0.066440</td>\n",
       "      <td>0.116860</td>\n",
       "      <td>-0.109021</td>\n",
       "      <td>-0.149601</td>\n",
       "      <td>0.145117</td>\n",
       "      <td>-0.085094</td>\n",
       "      <td>-0.252483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384124</td>\n",
       "      <td>-0.321982</td>\n",
       "      <td>0.134808</td>\n",
       "      <td>0.241099</td>\n",
       "      <td>0.292654</td>\n",
       "      <td>0.097723</td>\n",
       "      <td>-0.184306</td>\n",
       "      <td>-0.083339</td>\n",
       "      <td>-0.283843</td>\n",
       "      <td>-0.157734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.090709</td>\n",
       "      <td>0.174859</td>\n",
       "      <td>0.140899</td>\n",
       "      <td>-0.057479</td>\n",
       "      <td>0.116549</td>\n",
       "      <td>-0.112476</td>\n",
       "      <td>-0.153353</td>\n",
       "      <td>0.142980</td>\n",
       "      <td>-0.088394</td>\n",
       "      <td>-0.254144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382050</td>\n",
       "      <td>-0.313181</td>\n",
       "      <td>0.135114</td>\n",
       "      <td>0.244646</td>\n",
       "      <td>0.296318</td>\n",
       "      <td>0.097814</td>\n",
       "      <td>-0.171173</td>\n",
       "      <td>-0.084000</td>\n",
       "      <td>-0.279391</td>\n",
       "      <td>-0.159332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.078279</td>\n",
       "      <td>0.204316</td>\n",
       "      <td>0.148999</td>\n",
       "      <td>-0.021543</td>\n",
       "      <td>0.111497</td>\n",
       "      <td>-0.130965</td>\n",
       "      <td>-0.171405</td>\n",
       "      <td>0.135044</td>\n",
       "      <td>-0.094683</td>\n",
       "      <td>-0.262410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370794</td>\n",
       "      <td>-0.277083</td>\n",
       "      <td>0.140449</td>\n",
       "      <td>0.258526</td>\n",
       "      <td>0.310041</td>\n",
       "      <td>0.106022</td>\n",
       "      <td>-0.121177</td>\n",
       "      <td>-0.090657</td>\n",
       "      <td>-0.263047</td>\n",
       "      <td>-0.168325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.094309</td>\n",
       "      <td>0.167581</td>\n",
       "      <td>0.136895</td>\n",
       "      <td>-0.065817</td>\n",
       "      <td>0.119509</td>\n",
       "      <td>-0.106007</td>\n",
       "      <td>-0.147752</td>\n",
       "      <td>0.144524</td>\n",
       "      <td>-0.090200</td>\n",
       "      <td>-0.251473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386044</td>\n",
       "      <td>-0.321934</td>\n",
       "      <td>0.131944</td>\n",
       "      <td>0.241586</td>\n",
       "      <td>0.293588</td>\n",
       "      <td>0.092221</td>\n",
       "      <td>-0.181519</td>\n",
       "      <td>-0.080572</td>\n",
       "      <td>-0.282474</td>\n",
       "      <td>-0.156029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.071657</td>\n",
       "      <td>0.215079</td>\n",
       "      <td>0.159828</td>\n",
       "      <td>-0.010535</td>\n",
       "      <td>0.102920</td>\n",
       "      <td>-0.145193</td>\n",
       "      <td>-0.182488</td>\n",
       "      <td>0.133781</td>\n",
       "      <td>-0.083777</td>\n",
       "      <td>-0.267906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361913</td>\n",
       "      <td>-0.264541</td>\n",
       "      <td>0.149675</td>\n",
       "      <td>0.262146</td>\n",
       "      <td>0.312456</td>\n",
       "      <td>0.123034</td>\n",
       "      <td>-0.110793</td>\n",
       "      <td>-0.100100</td>\n",
       "      <td>-0.260828</td>\n",
       "      <td>-0.175860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.099300</td>\n",
       "      <td>0.171051</td>\n",
       "      <td>0.113441</td>\n",
       "      <td>-0.055002</td>\n",
       "      <td>0.139792</td>\n",
       "      <td>-0.085007</td>\n",
       "      <td>-0.135960</td>\n",
       "      <td>0.138514</td>\n",
       "      <td>-0.131899</td>\n",
       "      <td>-0.244767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399506</td>\n",
       "      <td>-0.315673</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.247724</td>\n",
       "      <td>0.303267</td>\n",
       "      <td>0.049723</td>\n",
       "      <td>-0.151173</td>\n",
       "      <td>-0.059610</td>\n",
       "      <td>-0.268908</td>\n",
       "      <td>-0.143908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.120755</td>\n",
       "      <td>0.120563</td>\n",
       "      <td>0.098982</td>\n",
       "      <td>-0.116438</td>\n",
       "      <td>0.148942</td>\n",
       "      <td>-0.052773</td>\n",
       "      <td>-0.104693</td>\n",
       "      <td>0.151996</td>\n",
       "      <td>-0.122083</td>\n",
       "      <td>-0.230420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419146</td>\n",
       "      <td>-0.377495</td>\n",
       "      <td>0.100325</td>\n",
       "      <td>0.224040</td>\n",
       "      <td>0.279936</td>\n",
       "      <td>0.034632</td>\n",
       "      <td>-0.236288</td>\n",
       "      <td>-0.047688</td>\n",
       "      <td>-0.296647</td>\n",
       "      <td>-0.128185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.080821</td>\n",
       "      <td>0.194199</td>\n",
       "      <td>0.152747</td>\n",
       "      <td>-0.035646</td>\n",
       "      <td>0.107646</td>\n",
       "      <td>-0.130816</td>\n",
       "      <td>-0.168929</td>\n",
       "      <td>0.139128</td>\n",
       "      <td>-0.081565</td>\n",
       "      <td>-0.261626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370704</td>\n",
       "      <td>-0.290018</td>\n",
       "      <td>0.144655</td>\n",
       "      <td>0.252554</td>\n",
       "      <td>0.303171</td>\n",
       "      <td>0.114832</td>\n",
       "      <td>-0.144891</td>\n",
       "      <td>-0.094189</td>\n",
       "      <td>-0.271775</td>\n",
       "      <td>-0.168762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.098598</td>\n",
       "      <td>0.155199</td>\n",
       "      <td>0.137028</td>\n",
       "      <td>-0.081875</td>\n",
       "      <td>0.118608</td>\n",
       "      <td>-0.101594</td>\n",
       "      <td>-0.142181</td>\n",
       "      <td>0.148595</td>\n",
       "      <td>-0.081621</td>\n",
       "      <td>-0.249111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388633</td>\n",
       "      <td>-0.337398</td>\n",
       "      <td>0.132973</td>\n",
       "      <td>0.235099</td>\n",
       "      <td>0.286652</td>\n",
       "      <td>0.095069</td>\n",
       "      <td>-0.206077</td>\n",
       "      <td>-0.080924</td>\n",
       "      <td>-0.291031</td>\n",
       "      <td>-0.154159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.070462</td>\n",
       "      <td>0.215094</td>\n",
       "      <td>0.164329</td>\n",
       "      <td>-0.011730</td>\n",
       "      <td>0.099072</td>\n",
       "      <td>-0.149472</td>\n",
       "      <td>-0.185061</td>\n",
       "      <td>0.134712</td>\n",
       "      <td>-0.076235</td>\n",
       "      <td>-0.269324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359184</td>\n",
       "      <td>-0.264893</td>\n",
       "      <td>0.153836</td>\n",
       "      <td>0.261323</td>\n",
       "      <td>0.310978</td>\n",
       "      <td>0.131045</td>\n",
       "      <td>-0.115274</td>\n",
       "      <td>-0.104110</td>\n",
       "      <td>-0.262964</td>\n",
       "      <td>-0.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.085016</td>\n",
       "      <td>0.180243</td>\n",
       "      <td>0.155317</td>\n",
       "      <td>-0.054399</td>\n",
       "      <td>0.104559</td>\n",
       "      <td>-0.128141</td>\n",
       "      <td>-0.164030</td>\n",
       "      <td>0.144220</td>\n",
       "      <td>-0.067834</td>\n",
       "      <td>-0.259725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372155</td>\n",
       "      <td>-0.307647</td>\n",
       "      <td>0.148053</td>\n",
       "      <td>0.244796</td>\n",
       "      <td>0.294553</td>\n",
       "      <td>0.122353</td>\n",
       "      <td>-0.174997</td>\n",
       "      <td>-0.096743</td>\n",
       "      <td>-0.282574</td>\n",
       "      <td>-0.167962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.113243</td>\n",
       "      <td>0.138624</td>\n",
       "      <td>0.103539</td>\n",
       "      <td>-0.094294</td>\n",
       "      <td>0.146195</td>\n",
       "      <td>-0.063719</td>\n",
       "      <td>-0.115527</td>\n",
       "      <td>0.147045</td>\n",
       "      <td>-0.126627</td>\n",
       "      <td>-0.235359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412493</td>\n",
       "      <td>-0.355329</td>\n",
       "      <td>0.103217</td>\n",
       "      <td>0.232626</td>\n",
       "      <td>0.288485</td>\n",
       "      <td>0.038934</td>\n",
       "      <td>-0.205223</td>\n",
       "      <td>-0.051404</td>\n",
       "      <td>-0.286430</td>\n",
       "      <td>-0.133477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.077178</td>\n",
       "      <td>0.208675</td>\n",
       "      <td>0.147408</td>\n",
       "      <td>-0.015474</td>\n",
       "      <td>0.113135</td>\n",
       "      <td>-0.131051</td>\n",
       "      <td>-0.172486</td>\n",
       "      <td>0.133290</td>\n",
       "      <td>-0.100294</td>\n",
       "      <td>-0.262756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370818</td>\n",
       "      <td>-0.271513</td>\n",
       "      <td>0.138659</td>\n",
       "      <td>0.261095</td>\n",
       "      <td>0.312993</td>\n",
       "      <td>0.102270</td>\n",
       "      <td>-0.110985</td>\n",
       "      <td>-0.089157</td>\n",
       "      <td>-0.259299</td>\n",
       "      <td>-0.168149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59 rows  768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "0   0.101676  0.166022  0.111098 -0.060879  0.141475 -0.080939 -0.132330   \n",
       "1   0.100653  0.162312  0.119864 -0.068043  0.133741 -0.087903 -0.135637   \n",
       "2   0.106309  0.155667  0.107252 -0.073241  0.144105 -0.073491 -0.125416   \n",
       "3   0.100119  0.162584  0.121525 -0.068138  0.132338 -0.089580 -0.136709   \n",
       "4   0.056343  0.243505  0.180198  0.020757  0.087308 -0.174954 -0.207066   \n",
       "5   0.075122  0.200287  0.166260 -0.031411  0.096477 -0.145878 -0.179410   \n",
       "6   0.088568  0.180552  0.141476 -0.050267  0.116417 -0.115111 -0.156279   \n",
       "7   0.106300  0.147490  0.118085 -0.086744  0.134318 -0.080781 -0.127864   \n",
       "8   0.080601  0.198142  0.148372 -0.029364  0.111640 -0.128106 -0.168232   \n",
       "9   0.106662  0.158896  0.101654 -0.067553  0.149100 -0.069359 -0.123696   \n",
       "10  0.095225  0.167210  0.133923 -0.065496  0.122028 -0.103049 -0.145888   \n",
       "11  0.089592  0.174886  0.145086 -0.058571  0.112970 -0.116462 -0.155753   \n",
       "12  0.065722  0.228881  0.164045  0.006188  0.100193 -0.154255 -0.191186   \n",
       "13  0.065711  0.220926  0.174593 -0.006951  0.090664 -0.161356 -0.193573   \n",
       "14  0.087525  0.176088  0.151316 -0.058697  0.107717 -0.122819 -0.159854   \n",
       "15  0.105971  0.144685  0.123031 -0.091706  0.129909 -0.084450 -0.129406   \n",
       "16  0.090464  0.177126  0.138828 -0.053986  0.118464 -0.111341 -0.153207   \n",
       "17  0.085750  0.177989  0.155517 -0.057370  0.104245 -0.127504 -0.163116   \n",
       "18  0.069572  0.213015  0.170437 -0.016067  0.093715 -0.154510 -0.187596   \n",
       "19  0.084322  0.175776  0.163840 -0.062476  0.096985 -0.134597 -0.166853   \n",
       "20  0.078927  0.194089  0.160058 -0.037760  0.101387 -0.137717 -0.173047   \n",
       "21  0.101706  0.161428  0.117048 -0.068428  0.136093 -0.084905 -0.133629   \n",
       "22  0.101308  0.156735  0.124751 -0.076577  0.129206 -0.090500 -0.135881   \n",
       "23  0.056815  0.232752  0.192612  0.003494  0.076005 -0.182801 -0.209241   \n",
       "24  0.095046  0.168641  0.132711 -0.063317  0.123156 -0.102422 -0.145849   \n",
       "25  0.106072  0.147841  0.118484 -0.086397  0.133999 -0.081289 -0.128252   \n",
       "26  0.089627  0.175530  0.144104 -0.057474  0.113850 -0.115765 -0.155487   \n",
       "27  0.100879  0.153561  0.130565 -0.082252  0.124031 -0.094857 -0.137749   \n",
       "28  0.097830  0.156124  0.138710 -0.081132  0.117227 -0.103531 -0.143562   \n",
       "29  0.079022  0.193393  0.160617 -0.038811  0.100864 -0.137993 -0.173049   \n",
       "30  0.074799  0.216780  0.145701 -0.004525  0.115112 -0.132401 -0.175208   \n",
       "31  0.074748  0.215268  0.147889 -0.007072  0.113144 -0.133924 -0.175766   \n",
       "32  0.092358  0.174694  0.134878 -0.056068  0.121688 -0.106699 -0.149845   \n",
       "33  0.131202  0.099057  0.087876 -0.141272  0.157072 -0.034344 -0.088553   \n",
       "34  0.119734  0.122561  0.100203 -0.114181  0.148025 -0.054664 -0.106300   \n",
       "35  0.086867  0.184653  0.142491 -0.045233  0.115811 -0.117577 -0.158727   \n",
       "36  0.096345  0.178008  0.115428 -0.046536  0.138536 -0.089443 -0.140265   \n",
       "37  0.102295  0.150635  0.129077 -0.085637  0.125117 -0.092372 -0.135566   \n",
       "38  0.072373  0.212728  0.160226 -0.013685  0.102431 -0.144708 -0.181642   \n",
       "39  0.090157  0.171263  0.147734 -0.063975  0.110474 -0.117648 -0.155611   \n",
       "40  0.101181  0.157292  0.124495 -0.075787  0.129461 -0.090461 -0.135989   \n",
       "41  0.081086  0.194969  0.150729 -0.034106  0.109422 -0.129181 -0.168129   \n",
       "42  0.098210  0.164486  0.126231 -0.066947  0.128434 -0.094746 -0.140259   \n",
       "43  0.081687  0.196511  0.146421 -0.030949  0.113205 -0.125656 -0.166376   \n",
       "44  0.094294  0.174451  0.127881 -0.054497  0.127658 -0.099964 -0.145744   \n",
       "45  0.097229  0.156222  0.140855 -0.081583  0.115399 -0.105604 -0.144830   \n",
       "46  0.093429  0.167747  0.140005 -0.066440  0.116860 -0.109021 -0.149601   \n",
       "47  0.090709  0.174859  0.140899 -0.057479  0.116549 -0.112476 -0.153353   \n",
       "48  0.078279  0.204316  0.148999 -0.021543  0.111497 -0.130965 -0.171405   \n",
       "49  0.094309  0.167581  0.136895 -0.065817  0.119509 -0.106007 -0.147752   \n",
       "50  0.071657  0.215079  0.159828 -0.010535  0.102920 -0.145193 -0.182488   \n",
       "51  0.099300  0.171051  0.113441 -0.055002  0.139792 -0.085007 -0.135960   \n",
       "52  0.120755  0.120563  0.098982 -0.116438  0.148942 -0.052773 -0.104693   \n",
       "53  0.080821  0.194199  0.152747 -0.035646  0.107646 -0.130816 -0.168929   \n",
       "54  0.098598  0.155199  0.137028 -0.081875  0.118608 -0.101594 -0.142181   \n",
       "55  0.070462  0.215094  0.164329 -0.011730  0.099072 -0.149472 -0.185061   \n",
       "56  0.085016  0.180243  0.155317 -0.054399  0.104559 -0.128141 -0.164030   \n",
       "57  0.113243  0.138624  0.103539 -0.094294  0.146195 -0.063719 -0.115527   \n",
       "58  0.077178  0.208675  0.147408 -0.015474  0.113135 -0.131051 -0.172486   \n",
       "\n",
       "         7         8         9    ...       758       759       760       761  \\\n",
       "0   0.139669 -0.132435 -0.243054  ...  0.402009 -0.321758  0.108202  0.245531   \n",
       "1   0.142704 -0.115222 -0.245092  ...  0.397498 -0.327109  0.116580  0.241978   \n",
       "2   0.142251 -0.131900 -0.239835  ...  0.406571 -0.334364  0.105403  0.240837   \n",
       "3   0.142960 -0.112618 -0.245667  ...  0.396433 -0.326906  0.118096  0.241814   \n",
       "4   0.128734 -0.068782 -0.279831  ...  0.343446 -0.230741  0.166432  0.273224   \n",
       "5   0.139949 -0.063001 -0.267058  ...  0.361205 -0.283531  0.156705  0.253239   \n",
       "6   0.141241 -0.091267 -0.255431  ...  0.380473 -0.306123  0.135231  0.247511   \n",
       "7   0.147174 -0.108203 -0.241656  ...  0.401770 -0.345461  0.116020  0.234570   \n",
       "8   0.136930 -0.091568 -0.261015  ...  0.372504 -0.284737  0.140321  0.255420   \n",
       "9   0.140033 -0.143473 -0.238700  ...  0.409266 -0.329874  0.099990  0.243555   \n",
       "10  0.144028 -0.094936 -0.250465  ...  0.387925 -0.322153  0.129223  0.241940   \n",
       "11  0.143842 -0.081387 -0.255467  ...  0.379508 -0.313490  0.138983  0.243888   \n",
       "12  0.130151 -0.086017 -0.271911  ...  0.356384 -0.247663  0.152564  0.268572   \n",
       "13  0.134942 -0.062948 -0.273685  ...  0.351709 -0.258459  0.162901  0.262474   \n",
       "14  0.144745 -0.071743 -0.257660  ...  0.375474 -0.312503  0.144658  0.243366   \n",
       "15  0.149118 -0.098011 -0.242667  ...  0.399378 -0.349368  0.120799  0.232194   \n",
       "16  0.141809 -0.093399 -0.253933  ...  0.382816 -0.310180  0.133033  0.246211   \n",
       "17  0.144997 -0.065978 -0.259351  ...  0.372520 -0.310477  0.148403  0.243583   \n",
       "18  0.136661 -0.064582 -0.270843  ...  0.355931 -0.267990  0.159637  0.259112   \n",
       "19  0.147450 -0.050519 -0.261540  ...  0.367954 -0.313922  0.156262  0.240893   \n",
       "20  0.140684 -0.069224 -0.263904  ...  0.366298 -0.290757  0.151424  0.251148   \n",
       "21  0.142407 -0.119350 -0.244035  ...  0.399394 -0.327981  0.114041  0.242036   \n",
       "22  0.145541 -0.103258 -0.245547  ...  0.395739 -0.334470  0.121507  0.238166   \n",
       "23  0.134827 -0.040694 -0.281649  ...  0.338243 -0.245182  0.178699  0.265322   \n",
       "24  0.143308 -0.097936 -0.250362  ...  0.388351 -0.320267  0.127997  0.242911   \n",
       "25  0.147142 -0.107770 -0.241849  ...  0.401452 -0.345056  0.116363  0.234680   \n",
       "26  0.143427 -0.083469 -0.255283  ...  0.379964 -0.312607  0.138028  0.244405   \n",
       "27  0.147786 -0.091360 -0.246760  ...  0.392901 -0.338910  0.127116  0.235436   \n",
       "28  0.148643 -0.079422 -0.249820  ...  0.387414 -0.336382  0.134461  0.235271   \n",
       "29  0.141027 -0.067817 -0.263945  ...  0.366110 -0.291671  0.151992  0.250682   \n",
       "30  0.130288 -0.108630 -0.263792  ...  0.370105 -0.261256  0.136487  0.265640   \n",
       "31  0.131237 -0.103937 -0.264186  ...  0.369106 -0.263324  0.138621  0.264447   \n",
       "32  0.141782 -0.098385 -0.252219  ...  0.385733 -0.312890  0.129558  0.245671   \n",
       "33  0.156709 -0.126205 -0.222752  ...  0.430510 -0.403421  0.091628  0.214864   \n",
       "34  0.151597 -0.121384 -0.231192  ...  0.417976 -0.375101  0.101308  0.224858   \n",
       "35  0.140112 -0.092334 -0.256546  ...  0.378975 -0.301088  0.135869  0.249464   \n",
       "36  0.136655 -0.133259 -0.246743  ...  0.396802 -0.307155  0.111329  0.250988   \n",
       "37  0.148432 -0.091882 -0.245724  ...  0.394433 -0.342440  0.125954  0.234184   \n",
       "38  0.134632 -0.081523 -0.267574  ...  0.362180 -0.267509  0.150215  0.260845   \n",
       "39  0.145575 -0.074498 -0.255597  ...  0.378684 -0.318231  0.141698  0.241508   \n",
       "40  0.145306 -0.104064 -0.245575  ...  0.395774 -0.333754  0.121230  0.238504   \n",
       "41  0.138457 -0.085473 -0.261140  ...  0.371761 -0.288891  0.142732  0.253328   \n",
       "42  0.143318 -0.106005 -0.247517  ...  0.393172 -0.324920  0.122309  0.241938   \n",
       "43  0.137058 -0.093741 -0.260084  ...  0.374038 -0.286613  0.138636  0.254928   \n",
       "44  0.140406 -0.109963 -0.249970  ...  0.390025 -0.312619  0.123105  0.246834   \n",
       "45  0.149057 -0.075889 -0.250514  ...  0.386093 -0.336436  0.136437  0.234927   \n",
       "46  0.145117 -0.085094 -0.252483  ...  0.384124 -0.321982  0.134808  0.241099   \n",
       "47  0.142980 -0.088394 -0.254144  ...  0.382050 -0.313181  0.135114  0.244646   \n",
       "48  0.135044 -0.094683 -0.262410  ...  0.370794 -0.277083  0.140449  0.258526   \n",
       "49  0.144524 -0.090200 -0.251473  ...  0.386044 -0.321934  0.131944  0.241586   \n",
       "50  0.133781 -0.083777 -0.267906  ...  0.361913 -0.264541  0.149675  0.262146   \n",
       "51  0.138514 -0.131899 -0.244767  ...  0.399506 -0.315673  0.110000  0.247724   \n",
       "52  0.151996 -0.122083 -0.230420  ...  0.419146 -0.377495  0.100325  0.224040   \n",
       "53  0.139128 -0.081565 -0.261626  ...  0.370704 -0.290018  0.144655  0.252554   \n",
       "54  0.148595 -0.081621 -0.249111  ...  0.388633 -0.337398  0.132973  0.235099   \n",
       "55  0.134712 -0.076235 -0.269324  ...  0.359184 -0.264893  0.153836  0.261323   \n",
       "56  0.144220 -0.067834 -0.259725  ...  0.372155 -0.307647  0.148053  0.244796   \n",
       "57  0.147045 -0.126627 -0.235359  ...  0.412493 -0.355329  0.103217  0.232626   \n",
       "58  0.133290 -0.100294 -0.262756  ...  0.370818 -0.271513  0.138659  0.261095   \n",
       "\n",
       "         762       763       764       765       766       767  \n",
       "0   0.301240  0.046613 -0.158749 -0.057618 -0.271242 -0.141855  \n",
       "1   0.296280  0.063005 -0.174850 -0.065498 -0.277967 -0.146006  \n",
       "2   0.296747  0.041949 -0.175322 -0.054388 -0.276510 -0.138154  \n",
       "3   0.295883  0.065906 -0.175976 -0.066973 -0.278572 -0.146946  \n",
       "4   0.321553  0.153308 -0.075126 -0.117708 -0.251043 -0.191316  \n",
       "5   0.302097  0.137608 -0.146418 -0.106111 -0.274042 -0.177013  \n",
       "6   0.299296  0.097641 -0.160521 -0.084406 -0.275761 -0.160536  \n",
       "7   0.288616  0.062966 -0.202308 -0.064195 -0.287286 -0.142722  \n",
       "8   0.306811  0.106209 -0.132728 -0.090216 -0.266983 -0.167018  \n",
       "9   0.300393  0.031299 -0.163343 -0.049339 -0.271625 -0.135638  \n",
       "10  0.294363  0.087007 -0.179274 -0.077931 -0.281312 -0.154366  \n",
       "11  0.294950  0.105264 -0.175313 -0.087729 -0.281369 -0.161597  \n",
       "12  0.318747  0.127630 -0.087791 -0.103595 -0.253371 -0.180301  \n",
       "13  0.310834  0.148092 -0.114053 -0.113143 -0.263859 -0.184749  \n",
       "14  0.293561  0.116105 -0.179185 -0.093258 -0.283516 -0.165150  \n",
       "15  0.285422  0.072364 -0.212795 -0.068655 -0.291568 -0.144952  \n",
       "16  0.298264  0.093649 -0.164625 -0.082112 -0.276848 -0.158569  \n",
       "17  0.293232  0.123184 -0.179644 -0.096964 -0.284215 -0.167716  \n",
       "18  0.307803  0.142361 -0.125495 -0.109591 -0.267303 -0.181265  \n",
       "19  0.289252  0.138471 -0.192346 -0.104421 -0.289702 -0.171863  \n",
       "20  0.300695  0.127873 -0.152433 -0.100704 -0.275337 -0.172692  \n",
       "21  0.296718  0.058178 -0.173772 -0.063007 -0.277230 -0.144347  \n",
       "22  0.291562  0.072884 -0.190747 -0.069958 -0.284122 -0.147771  \n",
       "23  0.311466  0.177683 -0.108776 -0.128972 -0.264339 -0.196333  \n",
       "24  0.295560  0.084546 -0.175236 -0.076823 -0.279752 -0.153936  \n",
       "25  0.288680  0.063602 -0.202015 -0.064544 -0.287235 -0.142992  \n",
       "26  0.295633  0.103379 -0.173060 -0.086842 -0.280459 -0.161167  \n",
       "27  0.287874  0.083907 -0.202834 -0.075198 -0.289072 -0.150412  \n",
       "28  0.286611  0.097870 -0.205938 -0.082406 -0.291199 -0.155212  \n",
       "29  0.300123  0.129015 -0.154365 -0.101215 -0.276080 -0.172885  \n",
       "30  0.318069  0.097519 -0.093284 -0.087482 -0.252924 -0.168498  \n",
       "31  0.316504  0.101735 -0.098460 -0.089460 -0.255005 -0.169443  \n",
       "32  0.298214  0.087128 -0.165465 -0.078639 -0.276633 -0.156055  \n",
       "33  0.271632  0.019392 -0.267585 -0.038201 -0.306103 -0.118815  \n",
       "34  0.280645  0.036383 -0.233568 -0.048737 -0.295858 -0.129157  \n",
       "35  0.301244  0.098582 -0.153445 -0.085232 -0.273431 -0.161727  \n",
       "36  0.306483  0.051794 -0.139441 -0.061248 -0.265084 -0.146072  \n",
       "37  0.286737  0.081874 -0.207114 -0.073928 -0.290370 -0.149150  \n",
       "38  0.311016  0.124238 -0.115830 -0.100499 -0.262631 -0.175706  \n",
       "39  0.292058  0.110744 -0.185114 -0.090158 -0.285117 -0.162459  \n",
       "40  0.291956  0.072310 -0.189391 -0.069719 -0.283618 -0.147720  \n",
       "41  0.304266  0.111074 -0.141349 -0.092375 -0.270284 -0.167793  \n",
       "42  0.295387  0.073884 -0.176940 -0.071129 -0.279512 -0.149785  \n",
       "43  0.306547  0.103079 -0.133992 -0.088509 -0.267172 -0.165709  \n",
       "44  0.300390  0.074719 -0.158935 -0.072410 -0.273463 -0.152238  \n",
       "45  0.285957  0.101669 -0.207894 -0.084315 -0.292155 -0.156386  \n",
       "46  0.292654  0.097723 -0.184306 -0.083339 -0.283843 -0.157734  \n",
       "47  0.296318  0.097814 -0.171173 -0.084000 -0.279391 -0.159332  \n",
       "48  0.310041  0.106022 -0.121177 -0.090657 -0.263047 -0.168325  \n",
       "49  0.293588  0.092221 -0.181519 -0.080572 -0.282474 -0.156029  \n",
       "50  0.312456  0.123034 -0.110793 -0.100100 -0.260828 -0.175860  \n",
       "51  0.303267  0.049723 -0.151173 -0.059610 -0.268908 -0.143908  \n",
       "52  0.279936  0.034632 -0.236288 -0.047688 -0.296647 -0.128185  \n",
       "53  0.303171  0.114832 -0.144891 -0.094189 -0.271775 -0.168762  \n",
       "54  0.286652  0.095069 -0.206077 -0.080924 -0.291031 -0.154159  \n",
       "55  0.310978  0.131045 -0.115274 -0.104110 -0.262964 -0.178292  \n",
       "56  0.294553  0.122353 -0.174997 -0.096743 -0.282574 -0.167962  \n",
       "57  0.288485  0.038934 -0.205223 -0.051404 -0.286430 -0.133477  \n",
       "58  0.312993  0.102270 -0.110985 -0.089157 -0.259299 -0.168149  \n",
       "\n",
       "[59 rows x 768 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "v= pd.DataFrame(Y_pred)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03172161366185263 0.033323184309242825\n"
     ]
    }
   ],
   "source": [
    "# separate data and target values\n",
    "x = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/bert_noun_embeddings.csv\")\n",
    "y = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/bert_adjnoun_embeddings.csv\")\n",
    "\n",
    "# tabular data structure with labeled axes\n",
    "# (rows and columns) using DataFrame\n",
    "\n",
    "df_x= x.loc[:, x.columns!=x.columns[0]]\n",
    "df_y= y.loc[:, y.columns!=y.columns[0]]\n",
    "\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression  \n",
    "from sklearn.metrics import mean_squared_error, r2_score  \n",
    "from sklearn.model_selection import cross_val_predict    \n",
    "# Define PLS object  \n",
    "pls = PLSRegression(n_components=5)    \n",
    "# Fit  \n",
    "# pls.fit(X, Y) \n",
    "pls2.fit(df_x, df_y)\n",
    "\n",
    "# Cross-validation  \n",
    "y_cv = cross_val_predict(pls, df_x, df_y, cv=10)    \n",
    "y_cv\n",
    "# # Calculate scores  \n",
    "score = r2_score(df_y, y_cv)  \n",
    "mse = mean_squared_error(df_y, y_cv)\n",
    "\n",
    "print (score, mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:292: UserWarning: Y residual constant at iteration 193\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1      335.677106\n",
       "2      366.365412\n",
       "3      170.686568\n",
       "4      387.328613\n",
       "5      153.593052\n",
       "          ...    \n",
       "764      0.000000\n",
       "765      0.000000\n",
       "766      0.000000\n",
       "767      0.000000\n",
       "768      0.000000\n",
       "Length: 768, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import cross_decomposition\n",
    "\n",
    "# X is a numpy ndarray with samples in rows and predictor variables in columns\n",
    "# y is one-dimensional ndarray containing the response variable\n",
    "\n",
    "total_variance_in_x = np.var(df_x, axis = 0)\n",
    "\n",
    "pls1 = cross_decomposition.PLSRegression(n_components = 768)\n",
    "pls1.fit(df_x, df_y) \n",
    "\n",
    "# variance in transformed X data for each latent vector:\n",
    "variance_in_x = np.var(pls1.x_scores_, axis = 0) \n",
    "\n",
    "# normalize variance by total variance:\n",
    "fractions_of_explained_variance = variance_in_x / total_variance_in_x\n",
    "fractions_of_explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 512)\n",
      "(194, 512)\n",
      "\n",
      "\n",
      "The X matrix: \n",
      "[[1.802 4.246 2.591 ... 1.701 2.341 2.738]\n",
      " [1.665 4.36  2.709 ... 1.745 2.511 2.587]\n",
      " [1.628 4.716 2.754 ... 1.784 2.341 2.392]\n",
      " ...\n",
      " [1.572 4.153 2.781 ... 1.541 2.353 2.893]\n",
      " [1.691 4.214 2.913 ... 1.535 2.411 3.209]\n",
      " [1.78  4.724 2.778 ... 1.771 2.311 2.614]]\n",
      "\n",
      "\n",
      "The Y matrix: \n",
      "[[1.533 4.287 2.843 ... 1.384 2.449 2.897]\n",
      " [1.396 4.192 2.725 ... 1.528 2.166 2.782]\n",
      " [1.688 4.453 3.12  ... 1.634 2.459 3.354]\n",
      " ...\n",
      " [1.317 4.346 3.554 ... 1.092 2.699 2.889]\n",
      " [1.664 5.334 2.66  ... 2.242 2.254 3.125]\n",
      " [1.902 3.799 2.553 ... 1.599 2.316 2.473]]\n",
      "(512, 512)\n",
      "\n",
      "\n",
      "Displaying the column-wise mean for the X matrix:\n",
      "[[1.672 4.311 2.824 2.854 2.12  3.049 2.295 1.574 2.478 3.515 2.594 2.653\n",
      "  2.112 2.422 1.893 2.016 1.659 3.221 2.178 3.164 3.25  1.79  2.54  3.745\n",
      "  3.302 2.656 2.506 1.802 2.54  2.085 1.661 3.184 2.48  3.383 1.675 1.661\n",
      "  1.93  2.611 3.453 1.789 3.724 2.592 2.302 3.757 3.548 2.762 2.238 4.021\n",
      "  3.254 2.486 1.278 2.765 2.717 0.863 2.288 3.009 3.492 1.528 1.76  3.471\n",
      "  2.654 2.481 0.971 2.355 2.452 3.131 2.748 2.144 3.138 2.558 2.726 2.391\n",
      "  1.818 2.39  1.851 1.658 3.265 2.497 2.149 2.471 1.951 2.576 2.455 1.638\n",
      "  2.067 2.842 2.398 2.072 2.165 1.406 3.641 6.674 1.567 2.737 2.632 2.798\n",
      "  3.436 2.575 1.615 1.649 3.013 4.005 3.766 2.215 2.333 4.048 2.539 1.722\n",
      "  2.81  2.112 2.269 2.252 2.076 2.914 2.801 2.849 1.633 3.282 3.025 2.906\n",
      "  1.642 2.318 2.083 2.292 1.844 1.692 1.641 1.7   2.546 2.606 2.539 2.481\n",
      "  2.131 3.257 3.622 3.131 4.101 2.603 2.627 1.813 3.198 1.672 1.636 2.292\n",
      "  1.564 3.431 0.678 1.506 2.254 1.603 2.84  2.299 3.025 3.022 3.611 2.034\n",
      "  3.916 2.979 3.449 1.649 2.637 3.748 4.022 2.577 3.493 1.936 3.518 3.037\n",
      "  2.196 1.677 2.063 2.329 2.163 2.524 1.018 1.587 3.568 4.142 2.596 1.684\n",
      "  1.82  2.075 1.2   1.461 2.431 2.418 1.118 1.719 3.214 1.97  3.474 2.492\n",
      "  0.588 3.311 3.187 3.542 1.925 1.848 3.21  2.049 1.39  2.154 1.246 1.353\n",
      "  2.458 1.697 4.94  2.631 2.122 2.583 2.44  2.011 2.982 1.91  1.82  1.69\n",
      "  3.093 2.829 2.484 1.992 2.636 2.584 3.999 2.302 3.816 2.851 1.662 3.63\n",
      "  2.242 2.895 1.372 2.101 2.601 2.706 3.684 1.339 3.111 1.662 1.978 2.301\n",
      "  2.504 1.931 2.786 2.355 1.307 2.921 1.562 3.11  1.854 2.379 2.397 2.283\n",
      "  2.594 1.521 1.733 2.089 2.758 1.123 2.15  3.258 1.994 1.914 3.094 1.674\n",
      "  3.482 3.418 3.01  2.132 2.317 1.743 1.5   3.141 2.404 1.518 2.627 2.292\n",
      "  1.2   1.492 2.142 1.487 2.733 2.983 2.049 2.854 2.547 1.91  3.471 2.001\n",
      "  2.829 3.275 4.095 1.503 2.104 2.133 2.683 2.011 1.458 1.688 1.834 1.927\n",
      "  1.617 1.95  2.868 2.995 3.136 2.696 2.279 1.866 2.475 2.296 1.363 2.573\n",
      "  1.346 2.701 3.787 2.578 1.962 2.431 1.948 2.814 2.604 2.376 2.142 1.889\n",
      "  1.843 2.257 2.685 2.518 2.025 2.982 1.711 2.618 3.037 3.374 2.448 1.653\n",
      "  1.337 2.404 2.359 2.239 1.76  2.938 1.956 1.111 3.046 1.492 2.281 1.97\n",
      "  2.189 2.875 1.542 4.082 1.904 2.63  2.218 1.652 2.827 1.532 3.12  3.544\n",
      "  1.594 2.719 2.906 2.159 2.901 1.946 1.15  2.836 1.869 2.032 3.399 1.62\n",
      "  3.201 2.651 2.289 1.636 2.064 3.584 1.774 2.372 3.357 2.559 3.905 2.759\n",
      "  2.676 2.7   1.444 2.978 2.942 1.717 2.904 2.258 2.328 2.239 3.068 2.842\n",
      "  1.838 2.763 2.253 2.109 1.249 2.372 1.846 2.656 3.072 1.501 1.176 2.609\n",
      "  2.327 2.248 1.857 3.207 4.302 1.462 2.428 3.79  2.602 1.082 1.76  1.595\n",
      "  2.836 2.794 3.036 3.801 2.194 1.753 1.559 1.981 4.429 1.971 4.153 2.493\n",
      "  3.258 1.607 3.063 2.765 4.582 1.122 2.747 2.728 3.291 1.72  2.965 2.782\n",
      "  3.207 2.416 1.774 4.046 2.24  3.029 2.092 3.005 2.737 2.231 2.114 1.962\n",
      "  2.289 3.185 1.957 2.473 2.405 2.102 2.165 2.276 3.751 3.493 2.05  1.493\n",
      "  2.216 2.835 1.878 2.293 2.91  2.034 2.798 3.04  2.21  2.822 2.979 1.119\n",
      "  1.942 1.701 1.751 2.472 2.429 1.836 2.807 3.541 2.271 2.974 1.796 2.146\n",
      "  5.427 3.735 2.274 3.622 2.502 3.053 1.252 1.07  2.455 1.617 1.979 2.348\n",
      "  3.017 2.303 2.68  3.507 2.933 1.619 2.442 2.845]]\n",
      "\n",
      "\n",
      "Displaying the column-wise mean for the Y matrix:\n",
      "[[1.685 4.332 2.834 2.886 2.128 3.061 2.281 1.484 2.424 3.564 2.591 2.74\n",
      "  2.139 2.474 1.881 1.986 1.68  3.277 2.203 3.298 3.237 1.64  2.514 3.787\n",
      "  3.309 2.616 2.49  1.772 2.596 2.059 1.775 3.217 2.421 3.345 1.569 1.715\n",
      "  1.919 2.691 3.486 1.784 3.704 2.658 2.266 3.773 3.527 2.772 2.239 4.075\n",
      "  3.395 2.481 1.3   2.695 2.577 0.839 2.224 3.054 3.54  1.548 1.754 3.524\n",
      "  2.615 2.576 1.005 2.336 2.499 3.138 2.768 2.112 3.141 2.468 2.75  2.455\n",
      "  1.82  2.441 1.864 1.721 3.249 2.519 2.144 2.533 1.985 2.643 2.439 1.618\n",
      "  2.015 2.851 2.394 2.017 2.172 1.398 3.634 6.659 1.564 2.8   2.678 2.892\n",
      "  3.388 2.605 1.656 1.672 3.03  4.    3.769 2.226 2.314 4.065 2.502 1.769\n",
      "  2.815 2.07  2.256 2.238 2.107 3.002 2.813 2.845 1.585 3.244 3.04  2.89\n",
      "  1.599 2.346 2.146 2.319 1.771 1.638 1.567 1.702 2.432 2.608 2.56  2.477\n",
      "  2.161 3.313 3.641 3.277 4.123 2.743 2.594 1.819 3.21  1.733 1.623 2.328\n",
      "  1.567 3.444 0.635 1.51  2.265 1.575 2.854 2.274 3.005 3.06  3.637 2.028\n",
      "  3.988 3.092 3.434 1.682 2.641 3.752 4.029 2.632 3.456 1.976 3.609 3.009\n",
      "  2.182 1.733 2.002 2.359 2.106 2.531 0.988 1.628 3.551 4.172 2.552 1.607\n",
      "  1.748 2.148 1.191 1.489 2.524 2.47  1.162 1.725 3.225 1.978 3.5   2.487\n",
      "  0.557 3.327 3.19  3.492 1.994 1.872 3.166 2.085 1.331 2.12  1.276 1.319\n",
      "  2.494 1.728 4.918 2.632 2.142 2.654 2.437 1.92  2.959 1.94  1.798 1.738\n",
      "  3.102 2.793 2.499 1.929 2.695 2.597 4.038 2.275 3.853 2.927 1.687 3.623\n",
      "  2.215 2.925 1.379 1.998 2.624 2.735 3.696 1.347 3.135 1.615 2.013 2.282\n",
      "  2.488 1.921 2.882 2.393 1.362 2.903 1.5   3.226 1.789 2.387 2.412 2.244\n",
      "  2.62  1.529 1.667 1.994 2.733 1.112 2.156 3.371 1.98  1.936 3.094 1.632\n",
      "  3.537 3.414 2.986 2.113 2.412 1.753 1.459 3.162 2.416 1.585 2.603 2.37\n",
      "  1.211 1.465 2.178 1.548 2.713 2.998 1.991 2.892 2.534 1.893 3.567 2.086\n",
      "  2.776 3.242 4.073 1.52  2.083 2.055 2.696 2.002 1.476 1.61  1.75  1.923\n",
      "  1.575 2.106 3.013 3.077 3.139 2.716 2.271 1.885 2.462 2.292 1.432 2.684\n",
      "  1.334 2.732 3.906 2.542 1.978 2.46  1.921 2.779 2.578 2.473 2.184 1.899\n",
      "  1.786 2.232 2.699 2.54  1.992 3.023 1.781 2.648 3.049 3.308 2.388 1.69\n",
      "  1.285 2.403 2.379 2.25  1.707 3.023 1.934 1.116 3.072 1.473 2.19  2.06\n",
      "  2.21  2.901 1.709 4.144 1.834 2.551 2.231 1.688 2.733 1.587 3.182 3.558\n",
      "  1.576 2.701 2.856 2.156 2.919 1.991 1.241 2.776 1.851 1.989 3.344 1.614\n",
      "  3.265 2.779 2.303 1.614 2.035 3.582 1.695 2.349 3.397 2.505 3.939 2.672\n",
      "  2.742 2.767 1.449 3.038 2.948 1.67  2.912 2.237 2.289 2.216 3.046 2.801\n",
      "  1.805 2.753 2.27  2.151 1.295 2.447 1.865 2.609 3.157 1.478 1.179 2.546\n",
      "  2.366 2.208 1.922 3.152 4.32  1.398 2.498 3.926 2.629 1.07  1.716 1.586\n",
      "  2.779 2.794 3.021 3.828 2.125 1.827 1.602 2.038 4.556 2.006 4.145 2.493\n",
      "  3.314 1.716 3.    2.756 4.579 1.187 2.69  2.625 3.237 1.697 3.019 2.84\n",
      "  3.177 2.419 1.746 4.191 2.111 3.102 2.069 3.    2.778 2.171 2.105 2.036\n",
      "  2.37  3.17  1.943 2.483 2.316 2.141 2.111 2.234 3.795 3.487 2.093 1.426\n",
      "  2.292 2.845 1.813 2.292 2.929 2.    2.808 3.038 2.26  2.829 2.973 1.075\n",
      "  1.958 1.646 1.808 2.492 2.48  1.933 2.821 3.466 2.259 2.984 1.84  2.198\n",
      "  5.41  3.747 2.287 3.617 2.487 2.984 1.278 1.065 2.484 1.606 1.95  2.294\n",
      "  3.085 2.278 2.67  3.499 2.995 1.604 2.435 2.911]]\n",
      "\n",
      "\n",
      "Displaying the matrix of regression coefficients:\n",
      "[[-0.147 -0.346 -0.064 ... -0.065  0.099  0.154]\n",
      " [-0.027 -0.133  0.15  ... -0.359  0.097 -0.065]\n",
      " [ 0.047 -0.362 -0.327 ...  0.113 -0.424  0.215]\n",
      " ...\n",
      " [-0.098  0.175 -0.341 ... -0.085 -0.057 -0.305]\n",
      " [-0.003  0.43   0.634 ...  0.018  0.291  0.234]\n",
      " [ 0.011  0.471  0.009 ... -0.103  0.185  0.314]]\n"
     ]
    }
   ],
   "source": [
    "# separate data and target values\n",
    "x = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/openl3_noun_embeddings.csv\")\n",
    "y = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/openl3_adjnoun_embeddings.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# tabular data structure with labeled axes\n",
    "# (rows and columns) using DataFrame\n",
    "\n",
    "df_x= x.loc[:, x.columns!=x.columns[0]]\n",
    "df_y= y.loc[:, y.columns!=y.columns[0]]\n",
    "\n",
    "\n",
    "# df_x.to_csv(\"xtest.csv\", header=None)\n",
    "# df_y.to_csv(\"ytest.csv\", header=None)\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# np.array(['1','2','3']).astype(np.float)\n",
    "\n",
    "import PartialLeastSquares as PLS\n",
    "\n",
    "XMatrix_file = \"xtest.csv\"\n",
    "YMatrix_file = \"ytest.csv\"\n",
    "\n",
    "print(df_x.shape)\n",
    "print(df_y.shape)\n",
    "\n",
    "\n",
    "pls = PLS.PartialLeastSquares(\n",
    "        XMatrix_file =  XMatrix_file,\n",
    "        YMatrix_file =  YMatrix_file,\n",
    "        epsilon      = 0.0001,\n",
    "      )\n",
    "x=pls.get_XMatrix_from_csv()\n",
    "y=pls.get_YMatrix_from_csv()\n",
    "\n",
    "B = pls.PLS()\n",
    "print(B.shape)\n",
    "\n",
    "print(\"\\n\\nDisplaying the column-wise mean for the X matrix:\")\n",
    "print(pls.mean0X)\n",
    "print(\"\\n\\nDisplaying the column-wise mean for the Y matrix:\")\n",
    "print(pls.mean0Y)\n",
    "print(\"\\n\\nDisplaying the matrix of regression coefficients:\")\n",
    "print(B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 512)\n",
      "(1, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(194, 512)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest= df_x\n",
    "print(Xtest.shape)\n",
    "print((pls.mean0X).shape)\n",
    "# Xtest.values-pls.mean0X\n",
    "Ytest =(Xtest.values-pls.mean0X) * B   +   pls.mean0Y\n",
    "# Xtest -  pls.mean0Y\n",
    "# pls.mean0X\n",
    "Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# Bmatx=pd.DataFrame(B)\n",
    "\n",
    "\n",
    "# x = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/bert_noun_embeddings.csv\")\n",
    "# y = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/bert_adjnoun_embeddings.csv\")\n",
    "\n",
    "# df_x= x.loc[:, x.columns!=x.columns[0]]\n",
    "# df_y= y.loc[:, y.columns!=y.columns[0]]\n",
    "\n",
    "\n",
    "# print(\"N:\",df_x.shape)\n",
    "# print (\"A:\",Bmatx.shape)\n",
    "# print (\"corpus AN:\", df_y.shape)\n",
    "\n",
    "# AN=np.dot(df_x,Bmatx)\n",
    "# # AN=df_x*Bmatx\n",
    "# # AN=df_x+Bmatx\n",
    "# # AN=np.add(df_x,Bmatx)\n",
    "# print(\"observed AN:\", AN.shape)\n",
    "# AN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 n_stab.csv\n",
      "2 n_button.csv\n",
      "3 n_pluck.csv\n",
      "4 n_wheel.csv\n",
      "5 n_radar.csv\n",
      "6 n_torch.csv\n",
      "7 n_gun.csv\n",
      "8 n_rain.csv\n",
      "9 n_goat.csv\n",
      "10 n_motorbike.csv\n",
      "11 n_speed.csv\n",
      "12 n_marker.csv\n",
      "13 n_paint.csv\n",
      "14 n_writing.csv\n",
      "15 n_harpoon.csv\n",
      "16 n_shutter.csv\n",
      "17 n_wings.csv\n",
      "18 n_synth.csv\n",
      "19 n_vacuum.csv\n",
      "20 n_vehicle.csv\n",
      "21 n_laser.csv\n",
      "22 n_camera.csv\n",
      "23 n_rail.csv\n",
      "24 n_coin.csv\n",
      "25 n_battle.csv\n",
      "26 n_scooter.csv\n",
      "27 n_handbrake.csv\n",
      "28 n_clap.csv\n",
      "29 n_countdown.csv\n",
      "30 n_footstep.csv\n",
      "31 n_clapping.csv\n",
      "32 n_kissing.csv\n",
      "33 n_motor.csv\n",
      "34 n_sneaker.csv\n",
      "35 n_kick.csv\n",
      "36 n_beat.csv\n",
      "37 n_leaf.csv\n",
      "38 n_guitar.csv\n",
      "39 n_running.csv\n",
      "40 n_applause.csv\n",
      "41 n_boot.csv\n",
      "42 n_whoosh.csv\n",
      "43 n_crutch.csv\n",
      "44 n_djembe.csv\n",
      "45 n_swipe.csv\n",
      "46 n_ratchet.csv\n",
      "47 n_highway.csv\n",
      "48 n_steam.csv\n",
      "49 n_pencil.csv\n",
      "50 n_bicycle.csv\n",
      "51 n_air.csv\n",
      "52 n_attack.csv\n",
      "53 n_foot.csv\n",
      "54 n_crush.csv\n",
      "55 n_knocking.csv\n",
      "56 n_departure.csv\n",
      "57 n_dressing.csv\n",
      "58 n_spin.csv\n",
      "59 n_jazz.csv\n",
      "60 n_push.csv\n",
      "61 n_melody.csv\n",
      "62 n_switch.csv\n",
      "63 n_beads.csv\n",
      "64 n_piano.csv\n",
      "65 n_drum.csv\n",
      "66 n_traffic.csv\n",
      "67 n_key.csv\n",
      "68 n_door.csv\n",
      "69 n_chalkboard.csv\n",
      "70 n_swing.csv\n",
      "71 n_flash.csv\n",
      "72 n_frog.csv\n",
      "73 n_train.csv\n",
      "74 n_zip.csv\n",
      "75 n_bass.csv\n",
      "76 n_radio.csv\n",
      "77 n_walk.csv\n",
      "78 n_shuffle.csv\n",
      "79 n_fan.csv\n",
      "80 n_drumstick.csv\n",
      "81 n_rocket.csv\n",
      "82 n_dog.csv\n",
      "83 n_balloon.csv\n",
      "84 n_snap.csv\n",
      "85 n_river.csv\n",
      "86 n_war.csv\n",
      "87 n_steps.csv\n",
      "88 n_stopwatch.csv\n",
      "89 n_ambulance.csv\n",
      "90 n_collision.csv\n",
      "91 n_brush.csv\n",
      "92 n_breath.csv\n",
      "93 n_spaceship.csv\n",
      "94 n_plane.csv\n",
      "95 n_kettle.csv\n",
      "96 n_crowd.csv\n",
      "97 n_smack.csv\n",
      "98 n_flute.csv\n",
      "99 n_blanket.csv\n",
      "100 n_swimming.csv\n",
      "101 n_slowdown.csv\n",
      "102 n_boiling.csv\n",
      "103 n_zipper.csv\n",
      "104 n_stream.csv\n",
      "105 n_jog.csv\n",
      "106 n_knife.csv\n",
      "107 n_puddle.csv\n",
      "108 n_wind.csv\n",
      "109 n_gunshot.csv\n",
      "110 n_beep.csv\n",
      "111 n_ticker.csv\n",
      "112 n_doorbell.csv\n",
      "113 n_breathing.csv\n",
      "114 n_telephone.csv\n",
      "115 n_fishing.csv\n",
      "116 n_kid.csv\n",
      "117 n_snow.csv\n",
      "118 n_wing.csv\n",
      "119 n_race.csv\n",
      "120 n_scissors.csv\n",
      "121 n_buzz.csv\n",
      "122 n_thrash.csv\n",
      "123 n_milk.csv\n",
      "124 n_generator.csv\n",
      "125 n_truck.csv\n",
      "126 n_tinkle.csv\n",
      "127 n_radiator.csv\n",
      "128 n_remix.csv\n",
      "129 n_hum.csv\n",
      "130 n_diesel.csv\n",
      "131 n_flyby.csv\n",
      "132 n_swoosh.csv\n",
      "133 n_bird.csv\n",
      "134 n_slide.csv\n",
      "135 n_erase.csv\n",
      "136 n_dragon.csv\n",
      "137 n_shower.csv\n",
      "138 n_broom.csv\n",
      "139 n_acceleration.csv\n",
      "140 n_candle.csv\n",
      "141 n_velcro.csv\n",
      "142 n_takeoff.csv\n",
      "143 n_trolley.csv\n",
      "144 n_seventies.csv\n",
      "145 n_pour.csv\n",
      "146 n_bike.csv\n",
      "147 n_energy.csv\n",
      "148 n_wiper.csv\n",
      "149 n_spray.csv\n",
      "150 n_drilling.csv\n",
      "151 n_signature.csv\n",
      "152 n_beast.csv\n",
      "153 n_whizz.csv\n",
      "154 n_electric.csv\n",
      "155 n_heart.csv\n",
      "156 n_boom.csv\n",
      "157 n_typing.csv\n",
      "158 n_fire.csv\n",
      "159 n_cards.csv\n",
      "160 n_alarm.csv\n",
      "161 n_burning.csv\n",
      "162 n_car.csv\n",
      "163 n_keyboard.csv\n",
      "164 n_stroke.csv\n",
      "165 n_type.csv\n",
      "166 n_typewriter.csv\n",
      "167 n_missile.csv\n",
      "168 n_transport.csv\n",
      "169 n_sweep.csv\n",
      "170 n_click.csv\n",
      "171 n_pump.csv\n",
      "172 n_shoes.csv\n",
      "173 n_drill.csv\n",
      "174 n_engine.csv\n",
      "175 n_heartbeat.csv\n",
      "176 n_run.csv\n",
      "177 n_water.csv\n",
      "178 n_noise.csv\n",
      "179 n_tick.csv\n",
      "180 n_knock.csv\n",
      "181 n_crawling.csv\n",
      "182 n_machine.csv\n",
      "183 n_cat.csv\n",
      "184 n_drive.csv\n",
      "185 n_glitch.csv\n",
      "186 n_helicopter.csv\n",
      "187 n_toboggan.csv\n",
      "188 n_card.csv\n",
      "189 n_phone.csv\n",
      "190 n_clock.csv\n",
      "191 n_jet.csv\n",
      "192 n_audio.csv\n",
      "193 n_sea.csv\n",
      "194 n_rythm.csv\n"
     ]
    }
   ],
   "source": [
    "# get embeddings\n",
    "rootdir= \"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/Noun-ogg-Embeddings/\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "p = Path(rootdir)\n",
    "itr=0\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "\n",
    "    if os.path.basename(subdir) == p.stem:\n",
    "        continue\n",
    "\n",
    "    i=0\n",
    "    df_name= pd.DataFrame()\n",
    "    name_list=[]\n",
    "    df_mean_noun=pd.DataFrame()\n",
    "    \n",
    "    for file in files:\n",
    "        if file==\".DS_Store\":\n",
    "            continue\n",
    "  \n",
    "        i=i+1\n",
    "        print(i, file)\n",
    "        read_file= pd.read_csv(rootdir+\"/\"+file)\n",
    "        base= os.path.basename(file)\n",
    "        base1= os.path.splitext(base)[0]\n",
    "            \n",
    "        name_list.append(base1)\n",
    "        embedding= read_file.drop(read_file.columns[0], axis=1)\n",
    "        \n",
    "        df= pd.DataFrame(embedding)\n",
    "        dfm=df.mean(axis=0)\n",
    "        df_mean_noun= df_mean_noun.append(dfm, ignore_index=True)\n",
    "        \n",
    "    df_name =pd.DataFrame(name_list)  \n",
    "    df_mean_noun= pd.concat([df_name, df_mean_noun],axis=1 ,ignore_index=True)\n",
    "#     df_mean_noun.to_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/openl3_noun_embeddings.csv\",index=False)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 512)\n",
      "N: (194, 512)\n",
      "A: (512, 512)\n",
      "corpus AN: (194, 512)\n",
      "observed AN: (194, 512)\n",
      "(194, 512)\n",
      "(0.3717249506048316, 0.0)\n",
      "SpearmanrResult(correlation=0.3356491098745792, pvalue=0.0)\n",
      "KendalltauResult(correlation=0.22844364648309606, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "x = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/openl3_noun_embeddings.csv\")\n",
    "y = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/openl3_adjnoun_embeddings.csv\")\n",
    "\n",
    "df_x= x.loc[:, x.columns!=x.columns[0]]\n",
    "df_y= y.loc[:, y.columns!=y.columns[0]]\n",
    "\n",
    "X= df_x\n",
    "Y= df_y\n",
    "\n",
    "pls = PLSRegression(n_components=40)\n",
    "pls.fit(X, Y)\n",
    "\n",
    "Y_pred = pls.predict(X)\n",
    "# pls.x_mean_(X)\n",
    "print(Y_pred.shape)\n",
    "\n",
    "print(\"N:\",df_x.shape)\n",
    "print (\"A:\",pls.coef_.shape)\n",
    "print (\"corpus AN:\", df_y.shape)\n",
    "\n",
    "AN=np.dot(df_x,pls.coef_)\n",
    "print(\"observed AN:\", AN.shape)\n",
    "\n",
    "# AN\n",
    "\n",
    "# calculate cosines\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_mean_noun= pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/openl3_adjnoun_embeddings.csv\")\n",
    "\n",
    "\n",
    "name_list= df_mean_noun.iloc[:, 0].values\n",
    "\n",
    "df_embed=df_mean_noun.drop(df_mean_noun.columns[0], axis=1)\n",
    "\n",
    "print (df_embed.shape)\n",
    "\n",
    "# Get distance matrix\n",
    "dist_out = 1-pairwise_distances(df_embed, metric=\"cosine\")\n",
    "\n",
    "# Get upper tirangle\n",
    "df_all_noun_cosines = pd.DataFrame(dist_out,index=name_list) \n",
    "df_all_noun_cosines.columns=name_list\n",
    "\n",
    "# ------getting upper triangle----\n",
    "values=pd.DataFrame(df_all_noun_cosines) \n",
    "values = values.where(np.triu(np.ones(values.shape)).astype(np.bool))\n",
    "\n",
    "# \"values\" is the cosine upper triangle\n",
    "values = values.stack().reset_index() \n",
    "values.columns = ['Noun1','Noun2','Cosines']\n",
    "\n",
    "cosine_upper_triangle=pd.DataFrame(values)\n",
    "# cosine_upper_triangle.to_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/n_openl3_cosines.csv\",index=False)\n",
    "# cosine_upper_triangle\n",
    "\n",
    "\n",
    "# calculate cosines\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# name_list= df_mean_noun.iloc[:, 0].values\n",
    "\n",
    "df_embed=AN\n",
    "\n",
    "# print (df_embed.shape)\n",
    "\n",
    "# Get distance matrix\n",
    "dist_out = 1-pairwise_distances(df_embed, metric=\"cosine\")\n",
    "\n",
    "# Get upper tirangle\n",
    "df_all_noun_cosines = pd.DataFrame(dist_out,index=name_list) \n",
    "df_all_noun_cosines.columns=name_list\n",
    "\n",
    "# ------getting upper triangle----\n",
    "values=pd.DataFrame(df_all_noun_cosines) \n",
    "values = values.where(np.triu(np.ones(values.shape)).astype(np.bool))\n",
    "\n",
    "# \"values\" is the cosine upper triangle\n",
    "values = values.stack().reset_index() \n",
    "values.columns = ['Noun1','Noun2','Cosines']\n",
    "\n",
    "cosine_upper_triangle_obs=pd.DataFrame(values)\n",
    "# cosine_upper_triangle.to_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/n_openl3_cosines.csv\",index=False)\n",
    "# cosine_upper_triangle_obs\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "# x = np.arange(10, 20)\n",
    "# y = np.array([2, 1, 4, 5, 8, 12, 18, 25, 96, 48])\n",
    "\n",
    "x=cosine_upper_triangle.Cosines\n",
    "y=cosine_upper_triangle_obs.Cosines\n",
    "\n",
    "print (scipy.stats.pearsonr(x, y))    # Pearson's r\n",
    "\n",
    "print (scipy.stats.spearmanr(x, y) )  # Spearman's rho\n",
    "\n",
    "print (scipy.stats.kendalltau(x, y))  # Kendall's tau\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing latent variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:292: UserWarning: Y residual constant at iteration 193\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:292: UserWarning: Y residual constant at iteration 193\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:292: UserWarning: Y residual constant at iteration 193\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:292: UserWarning: Y residual constant at iteration 193\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:292: UserWarning: Y residual constant at iteration 193\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:292: UserWarning: Y residual constant at iteration 193\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "comp=[]\n",
    "rho=[]\n",
    "\n",
    "for i in range (150, 200):\n",
    "\n",
    "#     x = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/bert_noun_embeddings.csv\")\n",
    "#     y = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/openl3_adjnoun_embeddings.csv\")\n",
    "\n",
    "#     df_x= x.loc[:, x.columns!=x.columns[0]]\n",
    "#     df_y= y.loc[:, y.columns!=y.columns[0]]\n",
    "\n",
    "#     X= df_x\n",
    "#     Y= df_y\n",
    "\n",
    "#     pls = PLSRegression(n_components=i)\n",
    "#     comp.append(i)\n",
    "#     pls.fit(X, Y)\n",
    "\n",
    "\n",
    "    x1 = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/bert_noun_embeddings.csv\")\n",
    "    x2 = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/openl3_noun_embeddings.csv\")\n",
    "    y1 = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/bert_adjnoun_embeddings.csv\")\n",
    "    y2 = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/openl3_adjnoun_embeddings.csv\")\n",
    "\n",
    "\n",
    "    x11= x1.loc[:, x1.columns!=x1.columns[0]]\n",
    "    x22= x2.loc[:, x2.columns!=x2.columns[0]]\n",
    "    y11= y1.loc[:, y1.columns!=y1.columns[0]]\n",
    "    y22= y2.loc[:, y2.columns!=y2.columns[0]]\n",
    "\n",
    "\n",
    "    X=pd.concat([x11, x22],axis=1, ignore_index=True)\n",
    "    Y=pd.concat([y11, y22],axis=1, ignore_index=True)\n",
    "\n",
    "    print (Y.shape)\n",
    "    print (X.shape)\n",
    "\n",
    "    pls = PLSRegression(n_components=i)\n",
    "    comp.append(i)\n",
    "    pls.fit(X, Y)\n",
    "\n",
    "#     Y_pred = pls.predict(y)\n",
    "    AN=np.dot(X,pls.coef_)\n",
    "\n",
    "    \n",
    "#     df_mean_noun= pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/openl3_adjnoun_embeddings.csv\")\n",
    "#     name_list= df_mean_noun.iloc[:, 0].values\n",
    "#     df_embed=df_mean_noun.drop(df_mean_noun.columns[0], axis=1)\n",
    "\n",
    "    y1 = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/bert_adjnoun_embeddings.csv\")\n",
    "    y2 = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/openl3_adjnoun_embeddings.csv\")\n",
    "\n",
    "    y11= y1.loc[:, y1.columns!=y1.columns[0]]\n",
    "    y22= y2.loc[:, y2.columns!=y2.columns[0]]\n",
    "\n",
    "    df_embed=pd.concat([y11, y22],axis=1, ignore_index=True)\n",
    "\n",
    "    name_list= y1.iloc[:, 0].values\n",
    "\n",
    "#     df_embed=y\n",
    "\n",
    "    # Get distance matrix\n",
    "    dist_out = 1-pairwise_distances(df_embed, metric=\"cosine\")\n",
    "\n",
    "    # Get upper tirangle\n",
    "    df_all_noun_cosines = pd.DataFrame(dist_out,index=name_list) \n",
    "    df_all_noun_cosines.columns=name_list\n",
    "\n",
    "    # ------getting upper triangle----\n",
    "    values=pd.DataFrame(df_all_noun_cosines) \n",
    "    values = values.where(np.triu(np.ones(values.shape)).astype(np.bool))\n",
    "\n",
    "    # \"values\" is the cosine upper triangle\n",
    "    values = values.stack().reset_index() \n",
    "    values.columns = ['Noun1','Noun2','Cosines']\n",
    "\n",
    "    cosine_upper_triangle=pd.DataFrame(values)\n",
    "\n",
    "\n",
    "\n",
    "    df_embed=AN\n",
    "\n",
    "    # Get distance matrix\n",
    "    dist_out = 1-pairwise_distances(df_embed, metric=\"cosine\")\n",
    "\n",
    "    # Get upper tirangle\n",
    "    df_all_noun_cosines = pd.DataFrame(dist_out,index=name_list) \n",
    "    df_all_noun_cosines.columns=name_list\n",
    "\n",
    "    # ------getting upper triangle----\n",
    "    values=pd.DataFrame(df_all_noun_cosines) \n",
    "    values = values.where(np.triu(np.ones(values.shape)).astype(np.bool))\n",
    "\n",
    "    # \"values\" is the cosine upper triangle\n",
    "    values = values.stack().reset_index() \n",
    "    values.columns = ['Noun1','Noun2','Cosines']\n",
    "\n",
    "    cosine_upper_triangle_obs=pd.DataFrame(values)\n",
    "\n",
    "    x=cosine_upper_triangle.Cosines\n",
    "    y=cosine_upper_triangle_obs.Cosines\n",
    "\n",
    "    rho.append(scipy.stats.spearmanr(x, y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RHO')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_decomposition import PLSRegression, PLSSVD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Plot results\n",
    "plt.plot(comp, rho, '-v')\n",
    "plt.xlabel('Number of principal components in regression')\n",
    "plt.ylabel('RHO')\n",
    "# plt.title('Salary')\n",
    "# plt.xlim(xmin=comp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 768)\n",
      "N: (194, 512)\n",
      "A: (512, 768)\n",
      "corpus AN: (194, 768)\n",
      "observed AN: (194, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01551827,  0.02596521, -0.02680373, ..., -0.00932623,\n",
       "        -0.03229363,  0.05928757],\n",
       "       [ 0.01887202,  0.0315767 , -0.03259644, ..., -0.01134177,\n",
       "        -0.03927279,  0.07210055],\n",
       "       [ 0.0189869 ,  0.03176893, -0.03279487, ..., -0.01141081,\n",
       "        -0.03951186,  0.07253946],\n",
       "       ...,\n",
       "       [ 0.01319478,  0.02207755, -0.02279052, ..., -0.00792985,\n",
       "        -0.02745843,  0.05041068],\n",
       "       [ 0.0069827 ,  0.01168347, -0.01206078, ..., -0.00419649,\n",
       "        -0.01453105,  0.02667742],\n",
       "       [ 0.01854142,  0.03102356, -0.03202543, ..., -0.01114309,\n",
       "        -0.03858483,  0.07083752]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "x = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/openl3_noun_embeddings.csv\")\n",
    "y = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/bert_adjnoun_embeddings.csv\")\n",
    "\n",
    "df_x= x.loc[:, x.columns!=x.columns[0]]\n",
    "df_y= y.loc[:, y.columns!=y.columns[0]]\n",
    "\n",
    "X= df_x\n",
    "Y= df_y\n",
    "\n",
    "pls = PLSRegression(n_components=1)\n",
    "pls.fit(X, Y)\n",
    "\n",
    "Y_pred = pls.predict(X)\n",
    "# pls.x_mean_(X)\n",
    "print(Y_pred.shape)\n",
    "\n",
    "print(\"N:\",df_x.shape)\n",
    "print (\"A:\",pls.coef_.shape)\n",
    "print (\"corpus AN:\", df_y.shape)\n",
    "\n",
    "AN=np.dot(df_x,pls.coef_)\n",
    "print(\"observed AN:\", AN.shape)\n",
    "\n",
    "AN\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "EAN=pd.DataFrame(AN)\n",
    "EAN\n",
    "\n",
    "# EAN.to_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/LR/Reg_openl3-AN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>n_fast helicopter</td>\n",
       "      <td>1.532763</td>\n",
       "      <td>4.287294</td>\n",
       "      <td>2.842828</td>\n",
       "      <td>2.968718</td>\n",
       "      <td>1.901738</td>\n",
       "      <td>3.223869</td>\n",
       "      <td>2.362051</td>\n",
       "      <td>1.504677</td>\n",
       "      <td>2.503704</td>\n",
       "      <td>...</td>\n",
       "      <td>1.821950</td>\n",
       "      <td>2.457626</td>\n",
       "      <td>3.317166</td>\n",
       "      <td>2.368294</td>\n",
       "      <td>2.630965</td>\n",
       "      <td>3.335762</td>\n",
       "      <td>2.999969</td>\n",
       "      <td>1.384075</td>\n",
       "      <td>2.448805</td>\n",
       "      <td>2.897105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>n_fast crawling</td>\n",
       "      <td>1.395982</td>\n",
       "      <td>4.192382</td>\n",
       "      <td>2.725104</td>\n",
       "      <td>2.608494</td>\n",
       "      <td>1.992640</td>\n",
       "      <td>3.180674</td>\n",
       "      <td>2.273008</td>\n",
       "      <td>1.500773</td>\n",
       "      <td>2.250038</td>\n",
       "      <td>...</td>\n",
       "      <td>1.416674</td>\n",
       "      <td>2.490629</td>\n",
       "      <td>2.641250</td>\n",
       "      <td>1.731947</td>\n",
       "      <td>2.369555</td>\n",
       "      <td>3.237322</td>\n",
       "      <td>2.593691</td>\n",
       "      <td>1.527624</td>\n",
       "      <td>2.165902</td>\n",
       "      <td>2.782044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>n_fast zip</td>\n",
       "      <td>1.688126</td>\n",
       "      <td>4.452752</td>\n",
       "      <td>3.120102</td>\n",
       "      <td>3.279495</td>\n",
       "      <td>2.141798</td>\n",
       "      <td>3.152549</td>\n",
       "      <td>2.121504</td>\n",
       "      <td>1.456523</td>\n",
       "      <td>2.241609</td>\n",
       "      <td>...</td>\n",
       "      <td>1.991433</td>\n",
       "      <td>2.608259</td>\n",
       "      <td>3.195506</td>\n",
       "      <td>2.018071</td>\n",
       "      <td>2.569738</td>\n",
       "      <td>3.558806</td>\n",
       "      <td>3.322090</td>\n",
       "      <td>1.634499</td>\n",
       "      <td>2.458545</td>\n",
       "      <td>3.353615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>n_fast heart</td>\n",
       "      <td>1.656335</td>\n",
       "      <td>4.254478</td>\n",
       "      <td>2.406494</td>\n",
       "      <td>3.013436</td>\n",
       "      <td>1.683758</td>\n",
       "      <td>3.276671</td>\n",
       "      <td>2.889117</td>\n",
       "      <td>1.523069</td>\n",
       "      <td>2.443207</td>\n",
       "      <td>...</td>\n",
       "      <td>1.594245</td>\n",
       "      <td>2.609958</td>\n",
       "      <td>3.215387</td>\n",
       "      <td>2.371075</td>\n",
       "      <td>2.403646</td>\n",
       "      <td>3.309705</td>\n",
       "      <td>3.162046</td>\n",
       "      <td>1.706863</td>\n",
       "      <td>2.290753</td>\n",
       "      <td>1.994055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>n_fast writing</td>\n",
       "      <td>1.669746</td>\n",
       "      <td>4.282705</td>\n",
       "      <td>2.840697</td>\n",
       "      <td>3.152903</td>\n",
       "      <td>2.144948</td>\n",
       "      <td>3.105286</td>\n",
       "      <td>2.188861</td>\n",
       "      <td>1.442194</td>\n",
       "      <td>2.359863</td>\n",
       "      <td>...</td>\n",
       "      <td>1.790960</td>\n",
       "      <td>2.463457</td>\n",
       "      <td>3.651066</td>\n",
       "      <td>2.160691</td>\n",
       "      <td>2.535074</td>\n",
       "      <td>3.471526</td>\n",
       "      <td>3.155708</td>\n",
       "      <td>1.482400</td>\n",
       "      <td>2.556990</td>\n",
       "      <td>3.238763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>n_fast collision</td>\n",
       "      <td>1.708631</td>\n",
       "      <td>4.473334</td>\n",
       "      <td>3.028483</td>\n",
       "      <td>2.927464</td>\n",
       "      <td>1.956790</td>\n",
       "      <td>3.027867</td>\n",
       "      <td>2.265047</td>\n",
       "      <td>1.230115</td>\n",
       "      <td>2.344376</td>\n",
       "      <td>...</td>\n",
       "      <td>1.591626</td>\n",
       "      <td>2.349178</td>\n",
       "      <td>3.229442</td>\n",
       "      <td>2.216702</td>\n",
       "      <td>2.677169</td>\n",
       "      <td>3.553365</td>\n",
       "      <td>3.488662</td>\n",
       "      <td>1.547112</td>\n",
       "      <td>2.513708</td>\n",
       "      <td>3.142413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>n_fast steam</td>\n",
       "      <td>1.620625</td>\n",
       "      <td>4.233724</td>\n",
       "      <td>2.746811</td>\n",
       "      <td>2.952249</td>\n",
       "      <td>2.159726</td>\n",
       "      <td>3.268308</td>\n",
       "      <td>2.255117</td>\n",
       "      <td>1.569186</td>\n",
       "      <td>2.706184</td>\n",
       "      <td>...</td>\n",
       "      <td>1.911342</td>\n",
       "      <td>1.827233</td>\n",
       "      <td>3.259744</td>\n",
       "      <td>2.533562</td>\n",
       "      <td>2.594197</td>\n",
       "      <td>3.341616</td>\n",
       "      <td>2.960495</td>\n",
       "      <td>1.515430</td>\n",
       "      <td>2.519829</td>\n",
       "      <td>3.075636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>n_fast tinkle</td>\n",
       "      <td>1.317451</td>\n",
       "      <td>4.346100</td>\n",
       "      <td>3.554153</td>\n",
       "      <td>2.458173</td>\n",
       "      <td>2.230771</td>\n",
       "      <td>2.841815</td>\n",
       "      <td>1.890952</td>\n",
       "      <td>1.613739</td>\n",
       "      <td>2.752204</td>\n",
       "      <td>...</td>\n",
       "      <td>2.318676</td>\n",
       "      <td>1.732738</td>\n",
       "      <td>2.253999</td>\n",
       "      <td>2.705086</td>\n",
       "      <td>2.351230</td>\n",
       "      <td>3.226836</td>\n",
       "      <td>2.864777</td>\n",
       "      <td>1.091537</td>\n",
       "      <td>2.698959</td>\n",
       "      <td>2.889287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>n_fast spaceship</td>\n",
       "      <td>1.663936</td>\n",
       "      <td>5.333527</td>\n",
       "      <td>2.659606</td>\n",
       "      <td>2.844930</td>\n",
       "      <td>2.133603</td>\n",
       "      <td>3.299240</td>\n",
       "      <td>2.418326</td>\n",
       "      <td>0.849058</td>\n",
       "      <td>2.857344</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000847</td>\n",
       "      <td>2.535991</td>\n",
       "      <td>3.183335</td>\n",
       "      <td>1.474155</td>\n",
       "      <td>2.985543</td>\n",
       "      <td>3.609639</td>\n",
       "      <td>3.220443</td>\n",
       "      <td>2.241876</td>\n",
       "      <td>2.254230</td>\n",
       "      <td>3.125394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>n_fast diesel</td>\n",
       "      <td>1.901846</td>\n",
       "      <td>3.798908</td>\n",
       "      <td>2.552547</td>\n",
       "      <td>2.538973</td>\n",
       "      <td>2.530990</td>\n",
       "      <td>2.831562</td>\n",
       "      <td>2.094559</td>\n",
       "      <td>2.253255</td>\n",
       "      <td>2.671391</td>\n",
       "      <td>...</td>\n",
       "      <td>2.021746</td>\n",
       "      <td>1.826308</td>\n",
       "      <td>2.247396</td>\n",
       "      <td>2.908516</td>\n",
       "      <td>3.206234</td>\n",
       "      <td>3.819265</td>\n",
       "      <td>2.324694</td>\n",
       "      <td>1.599377</td>\n",
       "      <td>2.316395</td>\n",
       "      <td>2.472910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows  513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5  \\\n",
       "0    n_fast helicopter  1.532763  4.287294  2.842828  2.968718  1.901738   \n",
       "1      n_fast crawling  1.395982  4.192382  2.725104  2.608494  1.992640   \n",
       "2           n_fast zip  1.688126  4.452752  3.120102  3.279495  2.141798   \n",
       "3         n_fast heart  1.656335  4.254478  2.406494  3.013436  1.683758   \n",
       "4       n_fast writing  1.669746  4.282705  2.840697  3.152903  2.144948   \n",
       "..                 ...       ...       ...       ...       ...       ...   \n",
       "189   n_fast collision  1.708631  4.473334  3.028483  2.927464  1.956790   \n",
       "190       n_fast steam  1.620625  4.233724  2.746811  2.952249  2.159726   \n",
       "191      n_fast tinkle  1.317451  4.346100  3.554153  2.458173  2.230771   \n",
       "192   n_fast spaceship  1.663936  5.333527  2.659606  2.844930  2.133603   \n",
       "193      n_fast diesel  1.901846  3.798908  2.552547  2.538973  2.530990   \n",
       "\n",
       "            6         7         8         9  ...       503       504  \\\n",
       "0    3.223869  2.362051  1.504677  2.503704  ...  1.821950  2.457626   \n",
       "1    3.180674  2.273008  1.500773  2.250038  ...  1.416674  2.490629   \n",
       "2    3.152549  2.121504  1.456523  2.241609  ...  1.991433  2.608259   \n",
       "3    3.276671  2.889117  1.523069  2.443207  ...  1.594245  2.609958   \n",
       "4    3.105286  2.188861  1.442194  2.359863  ...  1.790960  2.463457   \n",
       "..        ...       ...       ...       ...  ...       ...       ...   \n",
       "189  3.027867  2.265047  1.230115  2.344376  ...  1.591626  2.349178   \n",
       "190  3.268308  2.255117  1.569186  2.706184  ...  1.911342  1.827233   \n",
       "191  2.841815  1.890952  1.613739  2.752204  ...  2.318676  1.732738   \n",
       "192  3.299240  2.418326  0.849058  2.857344  ...  2.000847  2.535991   \n",
       "193  2.831562  2.094559  2.253255  2.671391  ...  2.021746  1.826308   \n",
       "\n",
       "          505       506       507       508       509       510       511  \\\n",
       "0    3.317166  2.368294  2.630965  3.335762  2.999969  1.384075  2.448805   \n",
       "1    2.641250  1.731947  2.369555  3.237322  2.593691  1.527624  2.165902   \n",
       "2    3.195506  2.018071  2.569738  3.558806  3.322090  1.634499  2.458545   \n",
       "3    3.215387  2.371075  2.403646  3.309705  3.162046  1.706863  2.290753   \n",
       "4    3.651066  2.160691  2.535074  3.471526  3.155708  1.482400  2.556990   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "189  3.229442  2.216702  2.677169  3.553365  3.488662  1.547112  2.513708   \n",
       "190  3.259744  2.533562  2.594197  3.341616  2.960495  1.515430  2.519829   \n",
       "191  2.253999  2.705086  2.351230  3.226836  2.864777  1.091537  2.698959   \n",
       "192  3.183335  1.474155  2.985543  3.609639  3.220443  2.241876  2.254230   \n",
       "193  2.247396  2.908516  3.206234  3.819265  2.324694  1.599377  2.316395   \n",
       "\n",
       "          512  \n",
       "0    2.897105  \n",
       "1    2.782044  \n",
       "2    3.353615  \n",
       "3    1.994055  \n",
       "4    3.238763  \n",
       "..        ...  \n",
       "189  3.142413  \n",
       "190  3.075636  \n",
       "191  2.889287  \n",
       "192  3.125394  \n",
       "193  2.472910  \n",
       "\n",
       "[194 rows x 513 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_noun= pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/openl3_adjnoun_embeddings.csv\")\n",
    "\n",
    "df_mean_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._multiarray_umath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Noun1</th>\n",
       "      <th>Noun2</th>\n",
       "      <th>Cosines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>fast stab</td>\n",
       "      <td>fast stab</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>fast stab</td>\n",
       "      <td>fast button</td>\n",
       "      <td>0.980059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>fast stab</td>\n",
       "      <td>fast pluck</td>\n",
       "      <td>0.984317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>fast stab</td>\n",
       "      <td>fast wheel</td>\n",
       "      <td>0.980912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>fast stab</td>\n",
       "      <td>fast radar</td>\n",
       "      <td>0.987878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18910</td>\n",
       "      <td>fast audio</td>\n",
       "      <td>fast sea</td>\n",
       "      <td>0.968052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18911</td>\n",
       "      <td>fast audio</td>\n",
       "      <td>fast rythm</td>\n",
       "      <td>0.973780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18912</td>\n",
       "      <td>fast sea</td>\n",
       "      <td>fast sea</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18913</td>\n",
       "      <td>fast sea</td>\n",
       "      <td>fast rythm</td>\n",
       "      <td>0.957958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18914</td>\n",
       "      <td>fast rythm</td>\n",
       "      <td>fast rythm</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18915 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Noun1        Noun2   Cosines\n",
       "0       fast stab    fast stab  1.000000\n",
       "1       fast stab  fast button  0.980059\n",
       "2       fast stab   fast pluck  0.984317\n",
       "3       fast stab   fast wheel  0.980912\n",
       "4       fast stab   fast radar  0.987878\n",
       "...           ...          ...       ...\n",
       "18910  fast audio     fast sea  0.968052\n",
       "18911  fast audio   fast rythm  0.973780\n",
       "18912    fast sea     fast sea  1.000000\n",
       "18913    fast sea   fast rythm  0.957958\n",
       "18914  fast rythm   fast rythm  1.000000\n",
       "\n",
       "[18915 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate cosines\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# df_mean_noun= pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/openl3_adjnoun_embeddings.csv\")\n",
    "\n",
    "y1 = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/bert_adjnoun_embeddings.csv\")\n",
    "y2 = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/openl3_adjnoun_embeddings.csv\")\n",
    "\n",
    "y11= y1.loc[:, y1.columns!=y1.columns[0]]\n",
    "y22= y2.loc[:, y2.columns!=y2.columns[0]]\n",
    "\n",
    "y=pd.concat([y11, y22],axis=1, ignore_index=True)\n",
    "\n",
    "name_list= y1.iloc[:, 0].values\n",
    "\n",
    "df_embed=y\n",
    "# df_embed=df_mean_noun.drop(df_mean_noun.columns[0], axis=1)\n",
    "\n",
    "print (df_embed.shape)\n",
    "\n",
    "# Get distance matrix\n",
    "dist_out = 1-pairwise_distances(df_embed, metric=\"cosine\")\n",
    "\n",
    "# Get upper tirangle\n",
    "df_all_noun_cosines = pd.DataFrame(dist_out,index=name_list) \n",
    "df_all_noun_cosines.columns=name_list\n",
    "\n",
    "# ------getting upper triangle----\n",
    "values=pd.DataFrame(df_all_noun_cosines) \n",
    "values = values.where(np.triu(np.ones(values.shape)).astype(np.bool))\n",
    "\n",
    "# \"values\" is the cosine upper triangle\n",
    "values = values.stack().reset_index() \n",
    "values.columns = ['Noun1','Noun2','Cosines']\n",
    "\n",
    "cosine_upper_triangle=pd.DataFrame(values)\n",
    "# cosine_upper_triangle.to_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/n_openl3_cosines.csv\",index=False)\n",
    "cosine_upper_triangle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n"
     ]
    }
   ],
   "source": [
    "# calculate cosines\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# name_list= df_mean_noun.iloc[:, 0].values\n",
    "\n",
    "df_embed=AN\n",
    "\n",
    "print (df_embed.shape)\n",
    "\n",
    "# Get distance matrix\n",
    "dist_out = 1-pairwise_distances(df_embed, metric=\"cosine\")\n",
    "\n",
    "# Get upper tirangle\n",
    "df_all_noun_cosines = pd.DataFrame(dist_out,index=name_list) \n",
    "df_all_noun_cosines.columns=name_list\n",
    "\n",
    "# ------getting upper triangle----\n",
    "values=pd.DataFrame(df_all_noun_cosines) \n",
    "values = values.where(np.triu(np.ones(values.shape)).astype(np.bool))\n",
    "\n",
    "# \"values\" is the cosine upper triangle\n",
    "values = values.stack().reset_index() \n",
    "values.columns = ['Noun1','Noun2','Cosines']\n",
    "\n",
    "cosine_upper_triangle_obs=pd.DataFrame(values)\n",
    "# cosine_upper_triangle.to_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/n_openl3_cosines.csv\",index=False)\n",
    "# cosine_upper_triangle_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8917783726152091, 0.0)\n",
      "SpearmanrResult(correlation=0.8935455899957101, pvalue=0.0)\n",
      "KendalltauResult(correlation=0.722006184992219, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "# x = np.arange(10, 20)\n",
    "# y = np.array([2, 1, 4, 5, 8, 12, 18, 25, 96, 48])\n",
    "\n",
    "x=cosine_upper_triangle.Cosines\n",
    "y=cosine_upper_triangle_obs.Cosines\n",
    "\n",
    "print (scipy.stats.pearsonr(x, y))    # Pearson's r\n",
    "\n",
    "print (scipy.stats.spearmanr(x, y) )  # Spearman's rho\n",
    "\n",
    "print (scipy.stats.kendalltau(x, y))  # Kendall's tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Noun1</th>\n",
       "      <th>Noun2</th>\n",
       "      <th>Euclidean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>n_fast helicopter</td>\n",
       "      <td>n_fast helicopter</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>n_fast helicopter</td>\n",
       "      <td>n_fast crawling</td>\n",
       "      <td>-7.651398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>n_fast helicopter</td>\n",
       "      <td>n_fast zip</td>\n",
       "      <td>-5.946731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>n_fast helicopter</td>\n",
       "      <td>n_fast heart</td>\n",
       "      <td>-7.519015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>n_fast helicopter</td>\n",
       "      <td>n_fast writing</td>\n",
       "      <td>-4.731313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18910</td>\n",
       "      <td>n_fast tinkle</td>\n",
       "      <td>n_fast spaceship</td>\n",
       "      <td>-12.889694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18911</td>\n",
       "      <td>n_fast tinkle</td>\n",
       "      <td>n_fast diesel</td>\n",
       "      <td>-10.135357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18912</td>\n",
       "      <td>n_fast spaceship</td>\n",
       "      <td>n_fast spaceship</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18913</td>\n",
       "      <td>n_fast spaceship</td>\n",
       "      <td>n_fast diesel</td>\n",
       "      <td>-14.991962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18914</td>\n",
       "      <td>n_fast diesel</td>\n",
       "      <td>n_fast diesel</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18915 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Noun1              Noun2  Euclidean\n",
       "0      n_fast helicopter  n_fast helicopter   1.000000\n",
       "1      n_fast helicopter    n_fast crawling  -7.651398\n",
       "2      n_fast helicopter         n_fast zip  -5.946731\n",
       "3      n_fast helicopter       n_fast heart  -7.519015\n",
       "4      n_fast helicopter     n_fast writing  -4.731313\n",
       "...                  ...                ...        ...\n",
       "18910      n_fast tinkle   n_fast spaceship -12.889694\n",
       "18911      n_fast tinkle      n_fast diesel -10.135357\n",
       "18912   n_fast spaceship   n_fast spaceship   0.999998\n",
       "18913   n_fast spaceship      n_fast diesel -14.991962\n",
       "18914      n_fast diesel      n_fast diesel   1.000000\n",
       "\n",
       "[18915 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate euclidean\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "df_mean_noun= pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/openl3_adjnoun_embeddings.csv\")\n",
    "\n",
    "name_list= df_mean_noun.iloc[:, 0].values\n",
    "\n",
    "df_embed=df_mean_noun.drop(df_mean_noun.columns[0], axis=1)\n",
    "\n",
    "# Get distance matrix\n",
    "dist_out = 1-pairwise_distances(df_embed, metric=\"euclidean\")\n",
    "\n",
    "# Get upper tirangle\n",
    "df_all_noun_cosines = pd.DataFrame(dist_out,index=name_list) \n",
    "df_all_noun_cosines.columns=name_list\n",
    "\n",
    "# ------getting upper triangle----\n",
    "values=pd.DataFrame(df_all_noun_cosines) \n",
    "values = values.where(np.triu(np.ones(values.shape)).astype(np.bool))\n",
    "\n",
    "# \"values\" is the cosine upper triangle\n",
    "values = values.stack().reset_index() \n",
    "values.columns = ['Noun1','Noun2','Euclidean']\n",
    "\n",
    "cosine_upper_triangle=pd.DataFrame(values)\n",
    "# cosine_upper_triangle.to_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/n_openl3_euclidean.csv\",index=False)\n",
    "cosine_upper_triangle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Noun1</th>\n",
       "      <th>Noun2</th>\n",
       "      <th>Euclidean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>n_fast helicopter</td>\n",
       "      <td>n_fast helicopter</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>n_fast helicopter</td>\n",
       "      <td>n_fast crawling</td>\n",
       "      <td>-1.955366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>n_fast helicopter</td>\n",
       "      <td>n_fast zip</td>\n",
       "      <td>-1.298895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>n_fast helicopter</td>\n",
       "      <td>n_fast heart</td>\n",
       "      <td>-1.745716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>n_fast helicopter</td>\n",
       "      <td>n_fast writing</td>\n",
       "      <td>-0.875637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18910</td>\n",
       "      <td>n_fast tinkle</td>\n",
       "      <td>n_fast spaceship</td>\n",
       "      <td>-3.846758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18911</td>\n",
       "      <td>n_fast tinkle</td>\n",
       "      <td>n_fast diesel</td>\n",
       "      <td>-2.755647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18912</td>\n",
       "      <td>n_fast spaceship</td>\n",
       "      <td>n_fast spaceship</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18913</td>\n",
       "      <td>n_fast spaceship</td>\n",
       "      <td>n_fast diesel</td>\n",
       "      <td>-4.444816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18914</td>\n",
       "      <td>n_fast diesel</td>\n",
       "      <td>n_fast diesel</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18915 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Noun1              Noun2  Euclidean\n",
       "0      n_fast helicopter  n_fast helicopter   1.000000\n",
       "1      n_fast helicopter    n_fast crawling  -1.955366\n",
       "2      n_fast helicopter         n_fast zip  -1.298895\n",
       "3      n_fast helicopter       n_fast heart  -1.745716\n",
       "4      n_fast helicopter     n_fast writing  -0.875637\n",
       "...                  ...                ...        ...\n",
       "18910      n_fast tinkle   n_fast spaceship  -3.846758\n",
       "18911      n_fast tinkle      n_fast diesel  -2.755647\n",
       "18912   n_fast spaceship   n_fast spaceship   1.000000\n",
       "18913   n_fast spaceship      n_fast diesel  -4.444816\n",
       "18914      n_fast diesel      n_fast diesel   1.000000\n",
       "\n",
       "[18915 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate euclidean\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "df_embed=AN\n",
    "\n",
    "# Get distance matrix\n",
    "dist_out = 1-pairwise_distances(df_embed, metric=\"euclidean\")\n",
    "\n",
    "# Get upper tirangle\n",
    "df_all_noun_cosines = pd.DataFrame(dist_out,index=name_list) \n",
    "df_all_noun_cosines.columns=name_list\n",
    "\n",
    "# ------getting upper triangle----\n",
    "values=pd.DataFrame(df_all_noun_cosines) \n",
    "values = values.where(np.triu(np.ones(values.shape)).astype(np.bool))\n",
    "\n",
    "# \"values\" is the cosine upper triangle\n",
    "values = values.stack().reset_index() \n",
    "values.columns = ['Noun1','Noun2','Euclidean']\n",
    "\n",
    "cosine_upper_triangle_obs=pd.DataFrame(values)\n",
    "# cosine_upper_triangle.to_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/n_openl3_euclidean.csv\",index=False)\n",
    "cosine_upper_triangle_obs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9887883318640791, 0.0)\n",
      "SpearmanrResult(correlation=0.9852437224741292, pvalue=0.0)\n",
      "KendalltauResult(correlation=0.8977073853320353, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "# x = np.arange(10, 20)\n",
    "# y = np.array([2, 1, 4, 5, 8, 12, 18, 25, 96, 48])\n",
    "\n",
    "x=cosine_upper_triangle.Euclidean\n",
    "y=cosine_upper_triangle_obs.Euclidean\n",
    "\n",
    "print (scipy.stats.pearsonr(x, y))    # Pearson's r\n",
    "\n",
    "print (scipy.stats.spearmanr(x, y) )  # Spearman's rho\n",
    "\n",
    "print (scipy.stats.kendalltau(x, y))  # Kendall's tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 512)\n",
      "N: (194, 512)\n",
      "A: (512, 512)\n",
      "corpus AN: (194, 512)\n",
      "observed AN: (194, 512)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/openl3_noun_embeddings.csv\")\n",
    "y = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/openl3_adjnoun_embeddings.csv\")\n",
    "\n",
    "df_x= x.loc[:, x.columns!=x.columns[0]]\n",
    "df_y= y.loc[:, y.columns!=y.columns[0]]\n",
    "\n",
    "X= df_x\n",
    "Y= df_y\n",
    "\n",
    "pls = PLSRegression(n_components=192)\n",
    "pls.fit(X, Y)\n",
    "\n",
    "Y_pred = pls.predict(X)\n",
    "# pls.x_mean_(X)\n",
    "print(Y_pred.shape)\n",
    "\n",
    "\n",
    "print(\"N:\",df_x.shape)\n",
    "print (\"A:\",pls.coef_.shape)\n",
    "print (\"corpus AN:\", df_y.shape)\n",
    "\n",
    "AN=np.dot(df_x,pls.coef_)\n",
    "print(\"observed AN:\", AN.shape)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "EAN=pd.DataFrame(AN)\n",
    "EAN\n",
    "\n",
    "EAN.to_csv(\"/Users/sabanazir/Desktop/Viva Tests/Reg_openl3-AN.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 1280)\n",
      "(194, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:79: ConvergenceWarning: Maximum number of iterations reached\n",
      "  ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:292: UserWarning: Y residual constant at iteration 193\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: (194, 1280)\n",
      "A: (1280, 1280)\n",
      "corpus AN: (194, 1280)\n",
      "observed AN: (194, 1280)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x1 = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/bert_noun_embeddings.csv\")\n",
    "x2 = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/openl3_noun_embeddings.csv\")\n",
    "y1 = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/bert_adjnoun_embeddings.csv\")\n",
    "y2 = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/openl3_adjnoun_embeddings.csv\")\n",
    "\n",
    "\n",
    "x11= x1.loc[:, x1.columns!=x1.columns[0]]\n",
    "x22= x2.loc[:, x2.columns!=x2.columns[0]]\n",
    "y11= y1.loc[:, y1.columns!=y1.columns[0]]\n",
    "y22= y2.loc[:, y2.columns!=y2.columns[0]]\n",
    "\n",
    "\n",
    "x=pd.concat([x11, x22],axis=1, ignore_index=True)\n",
    "y=pd.concat([y11, y22],axis=1, ignore_index=True)\n",
    "\n",
    "print (x.shape)\n",
    "print (y.shape)\n",
    "\n",
    "pls = PLSRegression(n_components=194)\n",
    "pls.fit(x, y)\n",
    "\n",
    "\n",
    "print(\"N:\",x.shape)\n",
    "print (\"A:\",pls.coef_.shape)\n",
    "print (\"corpus AN:\", y.shape)\n",
    "\n",
    "AN=np.dot(x,pls.coef_)\n",
    "print(\"observed AN:\", AN.shape)\n",
    "\n",
    "AN\n",
    "\n",
    "import pandas as pd\n",
    "EAN=pd.DataFrame(AN)\n",
    "EAN\n",
    "\n",
    "\n",
    "EAN.to_csv(\"/Users/sabanazir/Desktop/Viva Tests/Reg_openl3-cocatAN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSLR Non-Averaging Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: (512, 17704)\n",
      "A: (17704, 5657)\n",
      "corpus AN: (512, 5657)\n",
      "observed AN: (512, 5657)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.429, 1.544, 1.552, ..., 1.546, 1.69 , 1.436],\n",
       "       [2.285, 1.529, 1.863, ..., 0.945, 2.479, 1.793],\n",
       "       [3.714, 4.857, 2.774, ..., 2.636, 3.466, 3.465],\n",
       "       ...,\n",
       "       [2.553, 3.45 , 2.048, ..., 2.052, 2.304, 2.689],\n",
       "       [1.486, 2.001, 1.615, ..., 1.476, 1.311, 1.593],\n",
       "       [2.041, 3.33 , 1.491, ..., 1.257, 1.75 , 1.612]])"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "x = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Nouns/noAvg_openl3_noun_embeddings.csv\")\n",
    "y = pd.read_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/fast/Adj-Nouns/noAvg_openl3_Adjnoun_embeddings.csv\")\n",
    "\n",
    "\n",
    "# print(\"N:\",x.shape)\n",
    "# print (\"corpus AN:\", y.shape)\n",
    "\n",
    "pls = PLSRegression(n_components=43)\n",
    "pls.fit(x.T, y.T)\n",
    "\n",
    "Y_pred = pls.predict(x.T)\n",
    "# pls.x_mean_(X)\n",
    "# print(Y_pred.shape)\n",
    "\n",
    "print(\"N:\",x.T.shape)\n",
    "print (\"A:\",pls.coef_.shape)\n",
    "print (\"corpus AN:\", y.T.shape)\n",
    "\n",
    "AN=np.dot(x.T,pls.coef_)\n",
    "print(\"observed AN:\", AN.shape)\n",
    "\n",
    "AN\n",
    "\n",
    "\n",
    "# (194, 512)\n",
    "# N: (194, 512)\n",
    "# A: (512, 512)\n",
    "# corpus AN: (194, 512)\n",
    "# observed AN: (194, 512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "EAN=pd.DataFrame(AN.T)\n",
    "EAN\n",
    "\n",
    "EAN.to_csv(\"/Users/sabanazir/Documents/Adj-Noun Composition/LR/NoAvgReg_openl3-AN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.428749</td>\n",
       "      <td>2.285277</td>\n",
       "      <td>3.714172</td>\n",
       "      <td>2.994503</td>\n",
       "      <td>3.741125</td>\n",
       "      <td>2.247929</td>\n",
       "      <td>0.863203</td>\n",
       "      <td>1.854477</td>\n",
       "      <td>2.029424</td>\n",
       "      <td>3.711918</td>\n",
       "      <td>...</td>\n",
       "      <td>2.505779</td>\n",
       "      <td>1.753336</td>\n",
       "      <td>2.728186</td>\n",
       "      <td>2.742959</td>\n",
       "      <td>1.808963</td>\n",
       "      <td>1.321867</td>\n",
       "      <td>1.353592</td>\n",
       "      <td>2.552710</td>\n",
       "      <td>1.485980</td>\n",
       "      <td>2.041499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.543748</td>\n",
       "      <td>1.528974</td>\n",
       "      <td>4.856602</td>\n",
       "      <td>3.704720</td>\n",
       "      <td>3.277331</td>\n",
       "      <td>2.332409</td>\n",
       "      <td>1.124689</td>\n",
       "      <td>1.474891</td>\n",
       "      <td>1.067108</td>\n",
       "      <td>4.818307</td>\n",
       "      <td>...</td>\n",
       "      <td>3.847236</td>\n",
       "      <td>2.216274</td>\n",
       "      <td>3.405103</td>\n",
       "      <td>3.350000</td>\n",
       "      <td>2.306859</td>\n",
       "      <td>2.890594</td>\n",
       "      <td>2.666166</td>\n",
       "      <td>3.450245</td>\n",
       "      <td>2.001424</td>\n",
       "      <td>3.330264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.551938</td>\n",
       "      <td>1.862901</td>\n",
       "      <td>2.773794</td>\n",
       "      <td>2.616536</td>\n",
       "      <td>2.654298</td>\n",
       "      <td>1.269373</td>\n",
       "      <td>0.601241</td>\n",
       "      <td>0.979090</td>\n",
       "      <td>1.156978</td>\n",
       "      <td>2.317137</td>\n",
       "      <td>...</td>\n",
       "      <td>1.696385</td>\n",
       "      <td>1.278118</td>\n",
       "      <td>2.306130</td>\n",
       "      <td>2.026977</td>\n",
       "      <td>1.785659</td>\n",
       "      <td>1.038082</td>\n",
       "      <td>1.265234</td>\n",
       "      <td>2.047624</td>\n",
       "      <td>1.615351</td>\n",
       "      <td>1.490619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.585982</td>\n",
       "      <td>2.237860</td>\n",
       "      <td>3.525830</td>\n",
       "      <td>3.164379</td>\n",
       "      <td>2.414964</td>\n",
       "      <td>1.715305</td>\n",
       "      <td>1.025892</td>\n",
       "      <td>1.811833</td>\n",
       "      <td>1.360627</td>\n",
       "      <td>3.468466</td>\n",
       "      <td>...</td>\n",
       "      <td>3.164331</td>\n",
       "      <td>1.385384</td>\n",
       "      <td>3.079437</td>\n",
       "      <td>2.471474</td>\n",
       "      <td>1.738836</td>\n",
       "      <td>2.137646</td>\n",
       "      <td>2.069138</td>\n",
       "      <td>2.784724</td>\n",
       "      <td>1.982980</td>\n",
       "      <td>2.194439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.550392</td>\n",
       "      <td>1.030657</td>\n",
       "      <td>3.797400</td>\n",
       "      <td>3.661783</td>\n",
       "      <td>2.886036</td>\n",
       "      <td>1.008441</td>\n",
       "      <td>0.894364</td>\n",
       "      <td>1.293854</td>\n",
       "      <td>0.932759</td>\n",
       "      <td>4.218868</td>\n",
       "      <td>...</td>\n",
       "      <td>3.055790</td>\n",
       "      <td>2.058720</td>\n",
       "      <td>3.498441</td>\n",
       "      <td>1.887469</td>\n",
       "      <td>2.139517</td>\n",
       "      <td>2.869253</td>\n",
       "      <td>1.626167</td>\n",
       "      <td>3.611859</td>\n",
       "      <td>2.047136</td>\n",
       "      <td>2.062602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5652</td>\n",
       "      <td>1.364658</td>\n",
       "      <td>2.449758</td>\n",
       "      <td>3.465831</td>\n",
       "      <td>2.541915</td>\n",
       "      <td>3.030885</td>\n",
       "      <td>2.094195</td>\n",
       "      <td>0.779995</td>\n",
       "      <td>1.493472</td>\n",
       "      <td>1.794096</td>\n",
       "      <td>3.271993</td>\n",
       "      <td>...</td>\n",
       "      <td>2.436159</td>\n",
       "      <td>1.318836</td>\n",
       "      <td>2.749466</td>\n",
       "      <td>2.209374</td>\n",
       "      <td>1.562676</td>\n",
       "      <td>1.269584</td>\n",
       "      <td>1.122849</td>\n",
       "      <td>2.423868</td>\n",
       "      <td>1.517444</td>\n",
       "      <td>1.772586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5653</td>\n",
       "      <td>1.578629</td>\n",
       "      <td>1.468150</td>\n",
       "      <td>2.691551</td>\n",
       "      <td>1.899859</td>\n",
       "      <td>3.497873</td>\n",
       "      <td>1.717685</td>\n",
       "      <td>0.647166</td>\n",
       "      <td>0.889626</td>\n",
       "      <td>1.163077</td>\n",
       "      <td>2.781362</td>\n",
       "      <td>...</td>\n",
       "      <td>1.602641</td>\n",
       "      <td>1.550738</td>\n",
       "      <td>2.051627</td>\n",
       "      <td>1.057617</td>\n",
       "      <td>1.867379</td>\n",
       "      <td>1.046103</td>\n",
       "      <td>0.585742</td>\n",
       "      <td>2.024021</td>\n",
       "      <td>1.501168</td>\n",
       "      <td>1.234296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5654</td>\n",
       "      <td>1.545778</td>\n",
       "      <td>0.945022</td>\n",
       "      <td>2.636338</td>\n",
       "      <td>2.135800</td>\n",
       "      <td>2.877021</td>\n",
       "      <td>1.578188</td>\n",
       "      <td>0.777555</td>\n",
       "      <td>0.750628</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>2.778410</td>\n",
       "      <td>...</td>\n",
       "      <td>1.516192</td>\n",
       "      <td>1.668255</td>\n",
       "      <td>2.206121</td>\n",
       "      <td>1.111348</td>\n",
       "      <td>1.930754</td>\n",
       "      <td>1.094820</td>\n",
       "      <td>0.510412</td>\n",
       "      <td>2.052026</td>\n",
       "      <td>1.475858</td>\n",
       "      <td>1.256723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5655</td>\n",
       "      <td>1.689593</td>\n",
       "      <td>2.478745</td>\n",
       "      <td>3.465703</td>\n",
       "      <td>2.343260</td>\n",
       "      <td>2.995995</td>\n",
       "      <td>1.969656</td>\n",
       "      <td>0.751525</td>\n",
       "      <td>1.510159</td>\n",
       "      <td>1.798042</td>\n",
       "      <td>3.135392</td>\n",
       "      <td>...</td>\n",
       "      <td>2.202567</td>\n",
       "      <td>1.317068</td>\n",
       "      <td>2.512757</td>\n",
       "      <td>2.404521</td>\n",
       "      <td>1.718228</td>\n",
       "      <td>1.225901</td>\n",
       "      <td>1.046582</td>\n",
       "      <td>2.304184</td>\n",
       "      <td>1.310977</td>\n",
       "      <td>1.750472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5656</td>\n",
       "      <td>1.435674</td>\n",
       "      <td>1.792765</td>\n",
       "      <td>3.465170</td>\n",
       "      <td>2.859585</td>\n",
       "      <td>2.915313</td>\n",
       "      <td>2.356125</td>\n",
       "      <td>0.613839</td>\n",
       "      <td>1.641848</td>\n",
       "      <td>1.419066</td>\n",
       "      <td>3.328685</td>\n",
       "      <td>...</td>\n",
       "      <td>2.071900</td>\n",
       "      <td>1.160701</td>\n",
       "      <td>2.476086</td>\n",
       "      <td>1.792008</td>\n",
       "      <td>1.740871</td>\n",
       "      <td>1.243890</td>\n",
       "      <td>1.385514</td>\n",
       "      <td>2.689091</td>\n",
       "      <td>1.592646</td>\n",
       "      <td>1.612472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5657 rows  512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     1.428749  2.285277  3.714172  2.994503  3.741125  2.247929  0.863203   \n",
       "1     1.543748  1.528974  4.856602  3.704720  3.277331  2.332409  1.124689   \n",
       "2     1.551938  1.862901  2.773794  2.616536  2.654298  1.269373  0.601241   \n",
       "3     1.585982  2.237860  3.525830  3.164379  2.414964  1.715305  1.025892   \n",
       "4     1.550392  1.030657  3.797400  3.661783  2.886036  1.008441  0.894364   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5652  1.364658  2.449758  3.465831  2.541915  3.030885  2.094195  0.779995   \n",
       "5653  1.578629  1.468150  2.691551  1.899859  3.497873  1.717685  0.647166   \n",
       "5654  1.545778  0.945022  2.636338  2.135800  2.877021  1.578188  0.777555   \n",
       "5655  1.689593  2.478745  3.465703  2.343260  2.995995  1.969656  0.751525   \n",
       "5656  1.435674  1.792765  3.465170  2.859585  2.915313  2.356125  0.613839   \n",
       "\n",
       "           7         8         9    ...       502       503       504  \\\n",
       "0     1.854477  2.029424  3.711918  ...  2.505779  1.753336  2.728186   \n",
       "1     1.474891  1.067108  4.818307  ...  3.847236  2.216274  3.405103   \n",
       "2     0.979090  1.156978  2.317137  ...  1.696385  1.278118  2.306130   \n",
       "3     1.811833  1.360627  3.468466  ...  3.164331  1.385384  3.079437   \n",
       "4     1.293854  0.932759  4.218868  ...  3.055790  2.058720  3.498441   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5652  1.493472  1.794096  3.271993  ...  2.436159  1.318836  2.749466   \n",
       "5653  0.889626  1.163077  2.781362  ...  1.602641  1.550738  2.051627   \n",
       "5654  0.750628  0.984907  2.778410  ...  1.516192  1.668255  2.206121   \n",
       "5655  1.510159  1.798042  3.135392  ...  2.202567  1.317068  2.512757   \n",
       "5656  1.641848  1.419066  3.328685  ...  2.071900  1.160701  2.476086   \n",
       "\n",
       "           505       506       507       508       509       510       511  \n",
       "0     2.742959  1.808963  1.321867  1.353592  2.552710  1.485980  2.041499  \n",
       "1     3.350000  2.306859  2.890594  2.666166  3.450245  2.001424  3.330264  \n",
       "2     2.026977  1.785659  1.038082  1.265234  2.047624  1.615351  1.490619  \n",
       "3     2.471474  1.738836  2.137646  2.069138  2.784724  1.982980  2.194439  \n",
       "4     1.887469  2.139517  2.869253  1.626167  3.611859  2.047136  2.062602  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5652  2.209374  1.562676  1.269584  1.122849  2.423868  1.517444  1.772586  \n",
       "5653  1.057617  1.867379  1.046103  0.585742  2.024021  1.501168  1.234296  \n",
       "5654  1.111348  1.930754  1.094820  0.510412  2.052026  1.475858  1.256723  \n",
       "5655  2.404521  1.718228  1.225901  1.046582  2.304184  1.310977  1.750472  \n",
       "5656  1.792008  1.740871  1.243890  1.385514  2.689091  1.592646  1.612472  \n",
       "\n",
       "[5657 rows x 512 columns]"
      ]
     },
     "execution_count": 899,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
